{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+gWbxoXkMu3rLc6OxQqlT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adimis-ai/Simple-Chatbot---2/blob/main/Simple_Chatbot_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77AStIDXrGEB"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import random\n",
        "data_path = \"human_text.txt\"\n",
        "data_path2 = \"robot_text.txt\"\n",
        "# Defining lines as a list of each line\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "  lines = f.read().split('\\n')\n",
        "with open(data_path2, 'r', encoding='utf-8') as f:\n",
        "  lines2 = f.read().split('\\n')\n",
        "lines = [re.sub(r\"\\[\\w+\\]\",'hi',line) for line in lines]\n",
        "lines = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines]\n",
        "lines2 = [re.sub(r\"\\[\\w+\\]\",'',line) for line in lines2]\n",
        "lines2 = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines2]\n",
        "# Grouping lines by response pair\n",
        "pairs = list(zip(lines,lines2))\n",
        "#random.shuffle(pairs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "input_docs = []\n",
        "target_docs = []\n",
        "input_tokens = set()\n",
        "target_tokens = set()\n",
        "for line in pairs[:400]:\n",
        "  input_doc, target_doc = line[0], line[1]\n",
        "  # Appending each input sentence to input_docs\n",
        "  input_docs.append(input_doc)\n",
        "  # Splitting words from punctuation  \n",
        "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
        "  # Redefine target_doc below and append it to target_docs\n",
        "  target_doc = '<START> ' + target_doc + ' <END>'\n",
        "  target_docs.append(target_doc)\n",
        "  \n",
        "  # Now we split up each sentence into words and add each unique word to our vocabulary set\n",
        "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
        "    if token not in input_tokens:\n",
        "      input_tokens.add(token)\n",
        "  for token in target_doc.split():\n",
        "    if token not in target_tokens:\n",
        "      target_tokens.add(token)\n",
        "input_tokens = sorted(list(input_tokens))\n",
        "target_tokens = sorted(list(target_tokens))\n",
        "num_encoder_tokens = len(input_tokens)\n",
        "num_decoder_tokens = len(target_tokens)\n",
        "\n",
        "input_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(input_tokens)])\n",
        "target_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(target_tokens)])\n",
        "\n",
        "reverse_input_features_dict = dict(\n",
        "    (i, token) for token, i in input_features_dict.items())\n",
        "reverse_target_features_dict = dict(\n",
        "    (i, token) for token, i in target_features_dict.items())\n",
        "\n",
        "\n",
        "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
        "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
        "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
        "        #Assign 1. for the current line, timestep, & word in encoder_input_data\n",
        "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
        "    \n",
        "    for timestep, token in enumerate(target_doc.split()):\n",
        "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
        "        if timestep > 0:\n",
        "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."
      ],
      "metadata": {
        "id": "ocULIdqerREE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pairs[:5])\n",
        "print(input_docs[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGEOyndRrX4C",
        "outputId": "ec8bad87-3fe6-4377-a7ad-31597eb2d4af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('', 'hi there how are you'), ('oh thanks i m fine this is an evening in my timezone', 'here is afternoon'), ('how do you feel today tell me something about yourself', 'my name is rdany but you can call me dany the r means robot i hope we can be virtual friends'), ('how many virtual friends have you got', 'i have many but not enough to fully understand humans beings'), ('is that forbidden for you to tell the exact number', 'i ve talked with 143 users counting 7294 lines of text')]\n",
            "['', 'oh thanks i m fine this is an evening in my timezone', 'how do you feel today tell me something about yourself', 'how many virtual friends have you got', 'is that forbidden for you to tell the exact number']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "from keras.models import Model\n",
        "#Dimensionality\n",
        "dimensionality = 256\n",
        "#The batch size and number of epochs\n",
        "batch_size = 10\n",
        "epochs = 600\n",
        "#Encoder\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
        "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_hidden, state_cell]\n",
        "#Decoder\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
        "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "#Model\n",
        "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "#Compiling\n",
        "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
        "#Training\n",
        "training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
        "training_model.save('training_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsL_yV5ermJH",
        "outputId": "a6fa2788-ba9a-445d-8e82-513d6af69766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "32/32 [==============================] - 22s 541ms/step - loss: 1.2382 - accuracy: 0.0227 - val_loss: 1.3534 - val_accuracy: 0.0200\n",
            "Epoch 2/600\n",
            "32/32 [==============================] - 16s 510ms/step - loss: 1.1805 - accuracy: 0.0239 - val_loss: 1.3697 - val_accuracy: 0.0200\n",
            "Epoch 3/600\n",
            "32/32 [==============================] - 17s 526ms/step - loss: 1.1766 - accuracy: 0.0237 - val_loss: 1.3944 - val_accuracy: 0.0198\n",
            "Epoch 4/600\n",
            "32/32 [==============================] - 16s 513ms/step - loss: 1.1752 - accuracy: 0.0239 - val_loss: 1.4125 - val_accuracy: 0.0200\n",
            "Epoch 5/600\n",
            "32/32 [==============================] - 17s 529ms/step - loss: 1.1737 - accuracy: 0.0240 - val_loss: 1.4316 - val_accuracy: 0.0200\n",
            "Epoch 6/600\n",
            "32/32 [==============================] - 16s 493ms/step - loss: 1.1734 - accuracy: 0.0239 - val_loss: 1.4476 - val_accuracy: 0.0200\n",
            "Epoch 7/600\n",
            "32/32 [==============================] - 17s 524ms/step - loss: 1.1713 - accuracy: 0.0240 - val_loss: 1.4628 - val_accuracy: 0.0200\n",
            "Epoch 8/600\n",
            "32/32 [==============================] - 16s 500ms/step - loss: 1.1706 - accuracy: 0.0239 - val_loss: 1.4836 - val_accuracy: 0.0200\n",
            "Epoch 9/600\n",
            "32/32 [==============================] - 18s 548ms/step - loss: 1.1702 - accuracy: 0.0241 - val_loss: 1.4981 - val_accuracy: 0.0200\n",
            "Epoch 10/600\n",
            "32/32 [==============================] - 16s 496ms/step - loss: 1.1685 - accuracy: 0.0241 - val_loss: 1.5173 - val_accuracy: 0.0200\n",
            "Epoch 11/600\n",
            "32/32 [==============================] - 16s 501ms/step - loss: 1.1678 - accuracy: 0.0240 - val_loss: 1.5337 - val_accuracy: 0.0200\n",
            "Epoch 12/600\n",
            "32/32 [==============================] - 15s 478ms/step - loss: 1.1677 - accuracy: 0.0239 - val_loss: 1.5485 - val_accuracy: 0.0200\n",
            "Epoch 13/600\n",
            "32/32 [==============================] - 16s 501ms/step - loss: 1.1676 - accuracy: 0.0239 - val_loss: 1.5651 - val_accuracy: 0.0200\n",
            "Epoch 14/600\n",
            "32/32 [==============================] - 16s 511ms/step - loss: 1.1664 - accuracy: 0.0240 - val_loss: 1.5763 - val_accuracy: 0.0200\n",
            "Epoch 15/600\n",
            "32/32 [==============================] - 18s 550ms/step - loss: 1.1672 - accuracy: 0.0241 - val_loss: 1.5924 - val_accuracy: 0.0200\n",
            "Epoch 16/600\n",
            "32/32 [==============================] - 18s 550ms/step - loss: 1.1646 - accuracy: 0.0239 - val_loss: 1.6009 - val_accuracy: 0.0200\n",
            "Epoch 17/600\n",
            "32/32 [==============================] - 16s 505ms/step - loss: 1.1633 - accuracy: 0.0239 - val_loss: 1.6165 - val_accuracy: 0.0198\n",
            "Epoch 18/600\n",
            "32/32 [==============================] - 16s 491ms/step - loss: 1.1645 - accuracy: 0.0239 - val_loss: 1.6135 - val_accuracy: 0.0200\n",
            "Epoch 19/600\n",
            "32/32 [==============================] - 16s 493ms/step - loss: 1.1623 - accuracy: 0.0241 - val_loss: 1.6265 - val_accuracy: 0.0200\n",
            "Epoch 20/600\n",
            "32/32 [==============================] - 15s 481ms/step - loss: 1.1609 - accuracy: 0.0242 - val_loss: 1.6351 - val_accuracy: 0.0198\n",
            "Epoch 21/600\n",
            "32/32 [==============================] - 16s 488ms/step - loss: 1.1587 - accuracy: 0.0241 - val_loss: 1.6409 - val_accuracy: 0.0195\n",
            "Epoch 22/600\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.1577 - accuracy: 0.0239 - val_loss: 1.6364 - val_accuracy: 0.0195\n",
            "Epoch 23/600\n",
            "32/32 [==============================] - 16s 516ms/step - loss: 1.1537 - accuracy: 0.0247 - val_loss: 1.6438 - val_accuracy: 0.0203\n",
            "Epoch 24/600\n",
            "32/32 [==============================] - 17s 518ms/step - loss: 1.1514 - accuracy: 0.0251 - val_loss: 1.6487 - val_accuracy: 0.0198\n",
            "Epoch 25/600\n",
            "32/32 [==============================] - 16s 502ms/step - loss: 1.1522 - accuracy: 0.0250 - val_loss: 1.6445 - val_accuracy: 0.0198\n",
            "Epoch 26/600\n",
            "32/32 [==============================] - 16s 497ms/step - loss: 1.1516 - accuracy: 0.0247 - val_loss: 1.6541 - val_accuracy: 0.0198\n",
            "Epoch 27/600\n",
            "32/32 [==============================] - 15s 475ms/step - loss: 1.1551 - accuracy: 0.0254 - val_loss: 1.6537 - val_accuracy: 0.0200\n",
            "Epoch 28/600\n",
            "32/32 [==============================] - 16s 491ms/step - loss: 1.1557 - accuracy: 0.0253 - val_loss: 1.6602 - val_accuracy: 0.0203\n",
            "Epoch 29/600\n",
            "32/32 [==============================] - 17s 550ms/step - loss: 1.1507 - accuracy: 0.0254 - val_loss: 1.6555 - val_accuracy: 0.0203\n",
            "Epoch 30/600\n",
            "32/32 [==============================] - 17s 520ms/step - loss: 1.1465 - accuracy: 0.0254 - val_loss: 1.6542 - val_accuracy: 0.0198\n",
            "Epoch 31/600\n",
            "32/32 [==============================] - 16s 499ms/step - loss: 1.1485 - accuracy: 0.0254 - val_loss: 1.6568 - val_accuracy: 0.0200\n",
            "Epoch 32/600\n",
            "32/32 [==============================] - 16s 494ms/step - loss: 1.1474 - accuracy: 0.0257 - val_loss: 1.6611 - val_accuracy: 0.0203\n",
            "Epoch 33/600\n",
            "32/32 [==============================] - 16s 514ms/step - loss: 1.1486 - accuracy: 0.0257 - val_loss: 1.6630 - val_accuracy: 0.0198\n",
            "Epoch 34/600\n",
            "32/32 [==============================] - 15s 469ms/step - loss: 1.1480 - accuracy: 0.0258 - val_loss: 1.6640 - val_accuracy: 0.0198\n",
            "Epoch 35/600\n",
            "32/32 [==============================] - 16s 502ms/step - loss: 1.1433 - accuracy: 0.0257 - val_loss: 1.6656 - val_accuracy: 0.0198\n",
            "Epoch 36/600\n",
            "32/32 [==============================] - 15s 469ms/step - loss: 1.1456 - accuracy: 0.0259 - val_loss: 1.6642 - val_accuracy: 0.0198\n",
            "Epoch 37/600\n",
            "32/32 [==============================] - 15s 480ms/step - loss: 1.1417 - accuracy: 0.0264 - val_loss: 1.6646 - val_accuracy: 0.0198\n",
            "Epoch 38/600\n",
            "32/32 [==============================] - 16s 492ms/step - loss: 1.1422 - accuracy: 0.0259 - val_loss: 1.6675 - val_accuracy: 0.0198\n",
            "Epoch 39/600\n",
            "32/32 [==============================] - 15s 481ms/step - loss: 1.1400 - accuracy: 0.0262 - val_loss: 1.6707 - val_accuracy: 0.0198\n",
            "Epoch 40/600\n",
            "32/32 [==============================] - 14s 439ms/step - loss: 1.1395 - accuracy: 0.0258 - val_loss: 1.6651 - val_accuracy: 0.0200\n",
            "Epoch 41/600\n",
            "32/32 [==============================] - 17s 520ms/step - loss: 1.1380 - accuracy: 0.0265 - val_loss: 1.6694 - val_accuracy: 0.0200\n",
            "Epoch 42/600\n",
            "32/32 [==============================] - 18s 541ms/step - loss: 1.1379 - accuracy: 0.0262 - val_loss: 1.6677 - val_accuracy: 0.0203\n",
            "Epoch 43/600\n",
            "32/32 [==============================] - 16s 501ms/step - loss: 1.1349 - accuracy: 0.0261 - val_loss: 1.6666 - val_accuracy: 0.0213\n",
            "Epoch 44/600\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.1344 - accuracy: 0.0266 - val_loss: 1.6667 - val_accuracy: 0.0205\n",
            "Epoch 45/600\n",
            "32/32 [==============================] - 15s 472ms/step - loss: 1.1347 - accuracy: 0.0264 - val_loss: 1.6688 - val_accuracy: 0.0203\n",
            "Epoch 46/600\n",
            "32/32 [==============================] - 18s 552ms/step - loss: 1.1340 - accuracy: 0.0262 - val_loss: 1.6707 - val_accuracy: 0.0200\n",
            "Epoch 47/600\n",
            "32/32 [==============================] - 14s 431ms/step - loss: 1.1333 - accuracy: 0.0264 - val_loss: 1.6697 - val_accuracy: 0.0200\n",
            "Epoch 48/600\n",
            "32/32 [==============================] - 15s 485ms/step - loss: 1.1331 - accuracy: 0.0264 - val_loss: 1.6683 - val_accuracy: 0.0200\n",
            "Epoch 49/600\n",
            "32/32 [==============================] - 15s 456ms/step - loss: 1.1264 - accuracy: 0.0268 - val_loss: 1.6684 - val_accuracy: 0.0215\n",
            "Epoch 50/600\n",
            "32/32 [==============================] - 16s 506ms/step - loss: 1.1265 - accuracy: 0.0266 - val_loss: 1.6644 - val_accuracy: 0.0213\n",
            "Epoch 51/600\n",
            "32/32 [==============================] - 15s 471ms/step - loss: 1.1289 - accuracy: 0.0268 - val_loss: 1.6753 - val_accuracy: 0.0198\n",
            "Epoch 52/600\n",
            "32/32 [==============================] - 15s 477ms/step - loss: 1.1272 - accuracy: 0.0269 - val_loss: 1.6628 - val_accuracy: 0.0200\n",
            "Epoch 53/600\n",
            "32/32 [==============================] - 16s 507ms/step - loss: 1.1271 - accuracy: 0.0272 - val_loss: 1.6596 - val_accuracy: 0.0198\n",
            "Epoch 54/600\n",
            "32/32 [==============================] - 16s 493ms/step - loss: 1.1243 - accuracy: 0.0276 - val_loss: 1.6740 - val_accuracy: 0.0207\n",
            "Epoch 55/600\n",
            "32/32 [==============================] - 15s 459ms/step - loss: 1.1244 - accuracy: 0.0276 - val_loss: 1.6753 - val_accuracy: 0.0207\n",
            "Epoch 56/600\n",
            "32/32 [==============================] - 15s 480ms/step - loss: 1.1236 - accuracy: 0.0275 - val_loss: 1.6743 - val_accuracy: 0.0203\n",
            "Epoch 57/600\n",
            "32/32 [==============================] - 16s 491ms/step - loss: 1.1209 - accuracy: 0.0268 - val_loss: 1.6742 - val_accuracy: 0.0223\n",
            "Epoch 58/600\n",
            "32/32 [==============================] - 16s 504ms/step - loss: 1.1198 - accuracy: 0.0278 - val_loss: 1.6749 - val_accuracy: 0.0217\n",
            "Epoch 59/600\n",
            "32/32 [==============================] - 15s 457ms/step - loss: 1.1218 - accuracy: 0.0271 - val_loss: 1.6647 - val_accuracy: 0.0205\n",
            "Epoch 60/600\n",
            "32/32 [==============================] - 15s 462ms/step - loss: 1.1214 - accuracy: 0.0278 - val_loss: 1.6764 - val_accuracy: 0.0203\n",
            "Epoch 61/600\n",
            "32/32 [==============================] - 15s 480ms/step - loss: 1.1176 - accuracy: 0.0281 - val_loss: 1.6741 - val_accuracy: 0.0215\n",
            "Epoch 62/600\n",
            "32/32 [==============================] - 16s 512ms/step - loss: 1.1155 - accuracy: 0.0279 - val_loss: 1.6764 - val_accuracy: 0.0205\n",
            "Epoch 63/600\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.1154 - accuracy: 0.0284 - val_loss: 1.6781 - val_accuracy: 0.0205\n",
            "Epoch 64/600\n",
            "32/32 [==============================] - 15s 480ms/step - loss: 1.1108 - accuracy: 0.0291 - val_loss: 1.6834 - val_accuracy: 0.0210\n",
            "Epoch 65/600\n",
            "32/32 [==============================] - 15s 478ms/step - loss: 1.1155 - accuracy: 0.0281 - val_loss: 1.6792 - val_accuracy: 0.0205\n",
            "Epoch 66/600\n",
            "32/32 [==============================] - 17s 540ms/step - loss: 1.1147 - accuracy: 0.0273 - val_loss: 1.6801 - val_accuracy: 0.0200\n",
            "Epoch 67/600\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 1.1184 - accuracy: 0.0279 - val_loss: 1.6771 - val_accuracy: 0.0207\n",
            "Epoch 68/600\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 1.1128 - accuracy: 0.0286 - val_loss: 1.6804 - val_accuracy: 0.0203\n",
            "Epoch 69/600\n",
            "32/32 [==============================] - 15s 458ms/step - loss: 1.1172 - accuracy: 0.0284 - val_loss: 1.6889 - val_accuracy: 0.0195\n",
            "Epoch 70/600\n",
            "32/32 [==============================] - 14s 435ms/step - loss: 1.1111 - accuracy: 0.0284 - val_loss: 1.6786 - val_accuracy: 0.0200\n",
            "Epoch 71/600\n",
            "32/32 [==============================] - 16s 506ms/step - loss: 1.1080 - accuracy: 0.0289 - val_loss: 1.6725 - val_accuracy: 0.0203\n",
            "Epoch 72/600\n",
            "32/32 [==============================] - 15s 459ms/step - loss: 1.1082 - accuracy: 0.0289 - val_loss: 1.6728 - val_accuracy: 0.0205\n",
            "Epoch 73/600\n",
            "32/32 [==============================] - 14s 444ms/step - loss: 1.1106 - accuracy: 0.0290 - val_loss: 1.6855 - val_accuracy: 0.0198\n",
            "Epoch 74/600\n",
            "32/32 [==============================] - 15s 458ms/step - loss: 1.1069 - accuracy: 0.0291 - val_loss: 1.6794 - val_accuracy: 0.0195\n",
            "Epoch 75/600\n",
            "32/32 [==============================] - 16s 487ms/step - loss: 1.1047 - accuracy: 0.0296 - val_loss: 1.6741 - val_accuracy: 0.0210\n",
            "Epoch 76/600\n",
            "32/32 [==============================] - 14s 456ms/step - loss: 1.1051 - accuracy: 0.0289 - val_loss: 1.6794 - val_accuracy: 0.0215\n",
            "Epoch 77/600\n",
            "32/32 [==============================] - 14s 451ms/step - loss: 1.1057 - accuracy: 0.0295 - val_loss: 1.6852 - val_accuracy: 0.0200\n",
            "Epoch 78/600\n",
            "32/32 [==============================] - 14s 444ms/step - loss: 1.1022 - accuracy: 0.0294 - val_loss: 1.6901 - val_accuracy: 0.0203\n",
            "Epoch 79/600\n",
            "32/32 [==============================] - 16s 488ms/step - loss: 1.0989 - accuracy: 0.0301 - val_loss: 1.6910 - val_accuracy: 0.0203\n",
            "Epoch 80/600\n",
            "32/32 [==============================] - 14s 441ms/step - loss: 1.1001 - accuracy: 0.0298 - val_loss: 1.6946 - val_accuracy: 0.0190\n",
            "Epoch 81/600\n",
            "32/32 [==============================] - 14s 454ms/step - loss: 1.1027 - accuracy: 0.0300 - val_loss: 1.6831 - val_accuracy: 0.0207\n",
            "Epoch 82/600\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 1.0972 - accuracy: 0.0304 - val_loss: 1.6796 - val_accuracy: 0.0198\n",
            "Epoch 83/600\n",
            "32/32 [==============================] - 15s 472ms/step - loss: 1.0956 - accuracy: 0.0305 - val_loss: 1.6882 - val_accuracy: 0.0217\n",
            "Epoch 84/600\n",
            "32/32 [==============================] - 15s 467ms/step - loss: 1.1097 - accuracy: 0.0299 - val_loss: 1.6835 - val_accuracy: 0.0205\n",
            "Epoch 85/600\n",
            "32/32 [==============================] - 16s 489ms/step - loss: 1.1279 - accuracy: 0.0283 - val_loss: 1.6844 - val_accuracy: 0.0213\n",
            "Epoch 86/600\n",
            "32/32 [==============================] - 16s 493ms/step - loss: 1.1195 - accuracy: 0.0296 - val_loss: 1.6876 - val_accuracy: 0.0190\n",
            "Epoch 87/600\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 1.0974 - accuracy: 0.0301 - val_loss: 1.6940 - val_accuracy: 0.0210\n",
            "Epoch 88/600\n",
            "32/32 [==============================] - 14s 452ms/step - loss: 1.0935 - accuracy: 0.0302 - val_loss: 1.6929 - val_accuracy: 0.0195\n",
            "Epoch 89/600\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.0927 - accuracy: 0.0305 - val_loss: 1.6902 - val_accuracy: 0.0200\n",
            "Epoch 90/600\n",
            "32/32 [==============================] - 14s 442ms/step - loss: 1.0910 - accuracy: 0.0309 - val_loss: 1.6939 - val_accuracy: 0.0207\n",
            "Epoch 91/600\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 1.0976 - accuracy: 0.0304 - val_loss: 1.6266 - val_accuracy: 0.0215\n",
            "Epoch 92/600\n",
            "32/32 [==============================] - 15s 468ms/step - loss: 1.0864 - accuracy: 0.0322 - val_loss: 1.6240 - val_accuracy: 0.0203\n",
            "Epoch 93/600\n",
            "32/32 [==============================] - 15s 452ms/step - loss: 1.0893 - accuracy: 0.0310 - val_loss: 1.6321 - val_accuracy: 0.0198\n",
            "Epoch 94/600\n",
            "32/32 [==============================] - 15s 469ms/step - loss: 1.0875 - accuracy: 0.0321 - val_loss: 1.6524 - val_accuracy: 0.0200\n",
            "Epoch 95/600\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 1.0871 - accuracy: 0.0316 - val_loss: 1.6690 - val_accuracy: 0.0207\n",
            "Epoch 96/600\n",
            "32/32 [==============================] - 15s 462ms/step - loss: 1.0864 - accuracy: 0.0320 - val_loss: 1.6700 - val_accuracy: 0.0215\n",
            "Epoch 97/600\n",
            "32/32 [==============================] - 15s 462ms/step - loss: 1.0837 - accuracy: 0.0316 - val_loss: 1.6848 - val_accuracy: 0.0207\n",
            "Epoch 98/600\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 1.1030 - accuracy: 0.0300 - val_loss: 1.6699 - val_accuracy: 0.0203\n",
            "Epoch 99/600\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 1.0827 - accuracy: 0.0322 - val_loss: 1.6888 - val_accuracy: 0.0200\n",
            "Epoch 100/600\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.0792 - accuracy: 0.0321 - val_loss: 1.7079 - val_accuracy: 0.0200\n",
            "Epoch 101/600\n",
            "32/32 [==============================] - 16s 492ms/step - loss: 1.0808 - accuracy: 0.0324 - val_loss: 1.6961 - val_accuracy: 0.0203\n",
            "Epoch 102/600\n",
            "32/32 [==============================] - 15s 472ms/step - loss: 1.0788 - accuracy: 0.0317 - val_loss: 1.7047 - val_accuracy: 0.0215\n",
            "Epoch 103/600\n",
            "32/32 [==============================] - 16s 502ms/step - loss: 1.0773 - accuracy: 0.0326 - val_loss: 1.6956 - val_accuracy: 0.0207\n",
            "Epoch 104/600\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 1.0800 - accuracy: 0.0326 - val_loss: 1.7098 - val_accuracy: 0.0203\n",
            "Epoch 105/600\n",
            "32/32 [==============================] - 18s 559ms/step - loss: 1.0791 - accuracy: 0.0322 - val_loss: 1.7045 - val_accuracy: 0.0198\n",
            "Epoch 106/600\n",
            "32/32 [==============================] - 16s 487ms/step - loss: 1.0784 - accuracy: 0.0321 - val_loss: 1.7135 - val_accuracy: 0.0223\n",
            "Epoch 107/600\n",
            "32/32 [==============================] - 15s 470ms/step - loss: 1.0772 - accuracy: 0.0322 - val_loss: 1.7054 - val_accuracy: 0.0205\n",
            "Epoch 108/600\n",
            "32/32 [==============================] - 15s 482ms/step - loss: 1.0731 - accuracy: 0.0333 - val_loss: 1.7155 - val_accuracy: 0.0213\n",
            "Epoch 109/600\n",
            "32/32 [==============================] - 15s 468ms/step - loss: 1.0717 - accuracy: 0.0331 - val_loss: 1.7108 - val_accuracy: 0.0198\n",
            "Epoch 110/600\n",
            "32/32 [==============================] - 16s 482ms/step - loss: 1.0706 - accuracy: 0.0327 - val_loss: 1.7132 - val_accuracy: 0.0205\n",
            "Epoch 111/600\n",
            "32/32 [==============================] - 16s 492ms/step - loss: 1.0696 - accuracy: 0.0331 - val_loss: 1.7158 - val_accuracy: 0.0207\n",
            "Epoch 112/600\n",
            "32/32 [==============================] - 15s 481ms/step - loss: 1.0697 - accuracy: 0.0329 - val_loss: 1.7005 - val_accuracy: 0.0203\n",
            "Epoch 113/600\n",
            "32/32 [==============================] - 16s 495ms/step - loss: 1.0730 - accuracy: 0.0333 - val_loss: 1.7156 - val_accuracy: 0.0207\n",
            "Epoch 114/600\n",
            "32/32 [==============================] - 15s 470ms/step - loss: 1.0728 - accuracy: 0.0335 - val_loss: 1.7165 - val_accuracy: 0.0203\n",
            "Epoch 115/600\n",
            "32/32 [==============================] - 14s 451ms/step - loss: 1.0621 - accuracy: 0.0340 - val_loss: 1.7157 - val_accuracy: 0.0203\n",
            "Epoch 116/600\n",
            "32/32 [==============================] - 15s 469ms/step - loss: 1.0644 - accuracy: 0.0339 - val_loss: 1.7148 - val_accuracy: 0.0223\n",
            "Epoch 117/600\n",
            "32/32 [==============================] - 15s 469ms/step - loss: 1.0706 - accuracy: 0.0329 - val_loss: 1.7050 - val_accuracy: 0.0203\n",
            "Epoch 118/600\n",
            "32/32 [==============================] - 17s 536ms/step - loss: 1.0617 - accuracy: 0.0335 - val_loss: 1.7148 - val_accuracy: 0.0203\n",
            "Epoch 119/600\n",
            "32/32 [==============================] - 15s 478ms/step - loss: 1.0618 - accuracy: 0.0338 - val_loss: 1.7088 - val_accuracy: 0.0203\n",
            "Epoch 120/600\n",
            "32/32 [==============================] - 15s 472ms/step - loss: 1.0628 - accuracy: 0.0339 - val_loss: 1.7121 - val_accuracy: 0.0205\n",
            "Epoch 121/600\n",
            "32/32 [==============================] - 14s 435ms/step - loss: 1.0594 - accuracy: 0.0344 - val_loss: 1.7148 - val_accuracy: 0.0210\n",
            "Epoch 122/600\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.0592 - accuracy: 0.0333 - val_loss: 1.7284 - val_accuracy: 0.0207\n",
            "Epoch 123/600\n",
            "32/32 [==============================] - 16s 492ms/step - loss: 1.0825 - accuracy: 0.0326 - val_loss: 1.7050 - val_accuracy: 0.0207\n",
            "Epoch 124/600\n",
            "32/32 [==============================] - 15s 482ms/step - loss: 1.0576 - accuracy: 0.0341 - val_loss: 1.7221 - val_accuracy: 0.0200\n",
            "Epoch 125/600\n",
            "32/32 [==============================] - 15s 459ms/step - loss: 1.0561 - accuracy: 0.0347 - val_loss: 1.7210 - val_accuracy: 0.0210\n",
            "Epoch 126/600\n",
            "32/32 [==============================] - 14s 436ms/step - loss: 1.0545 - accuracy: 0.0341 - val_loss: 1.7204 - val_accuracy: 0.0198\n",
            "Epoch 127/600\n",
            "32/32 [==============================] - 15s 457ms/step - loss: 1.0597 - accuracy: 0.0335 - val_loss: 1.6933 - val_accuracy: 0.0190\n",
            "Epoch 128/600\n",
            "32/32 [==============================] - 15s 476ms/step - loss: 1.0635 - accuracy: 0.0348 - val_loss: 1.7206 - val_accuracy: 0.0210\n",
            "Epoch 129/600\n",
            "32/32 [==============================] - 16s 485ms/step - loss: 1.0516 - accuracy: 0.0349 - val_loss: 1.7265 - val_accuracy: 0.0215\n",
            "Epoch 130/600\n",
            "32/32 [==============================] - 16s 500ms/step - loss: 1.0500 - accuracy: 0.0351 - val_loss: 1.7208 - val_accuracy: 0.0207\n",
            "Epoch 131/600\n",
            "32/32 [==============================] - 16s 509ms/step - loss: 1.0752 - accuracy: 0.0338 - val_loss: 1.6636 - val_accuracy: 0.0188\n",
            "Epoch 132/600\n",
            "32/32 [==============================] - 16s 497ms/step - loss: 1.2058 - accuracy: 0.0227 - val_loss: 1.6130 - val_accuracy: 0.0195\n",
            "Epoch 133/600\n",
            "32/32 [==============================] - 15s 472ms/step - loss: 1.1987 - accuracy: 0.0241 - val_loss: 1.6124 - val_accuracy: 0.0198\n",
            "Epoch 134/600\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 1.1851 - accuracy: 0.0237 - val_loss: 1.6151 - val_accuracy: 0.0205\n",
            "Epoch 135/600\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 1.1681 - accuracy: 0.0237 - val_loss: 1.6251 - val_accuracy: 0.0195\n",
            "Epoch 136/600\n",
            "32/32 [==============================] - 15s 457ms/step - loss: 1.1586 - accuracy: 0.0247 - val_loss: 1.6289 - val_accuracy: 0.0203\n",
            "Epoch 137/600\n",
            "32/32 [==============================] - 15s 454ms/step - loss: 1.1593 - accuracy: 0.0261 - val_loss: 1.6322 - val_accuracy: 0.0200\n",
            "Epoch 138/600\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 1.1479 - accuracy: 0.0266 - val_loss: 1.6428 - val_accuracy: 0.0207\n",
            "Epoch 139/600\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.1345 - accuracy: 0.0279 - val_loss: 1.6605 - val_accuracy: 0.0223\n",
            "Epoch 140/600\n",
            "32/32 [==============================] - 15s 472ms/step - loss: 1.1346 - accuracy: 0.0270 - val_loss: 1.6602 - val_accuracy: 0.0215\n",
            "Epoch 141/600\n",
            "32/32 [==============================] - 15s 480ms/step - loss: 1.1263 - accuracy: 0.0281 - val_loss: 1.6736 - val_accuracy: 0.0215\n",
            "Epoch 142/600\n",
            "32/32 [==============================] - 17s 525ms/step - loss: 1.1226 - accuracy: 0.0283 - val_loss: 1.6587 - val_accuracy: 0.0210\n",
            "Epoch 143/600\n",
            "32/32 [==============================] - 16s 510ms/step - loss: 1.1205 - accuracy: 0.0289 - val_loss: 1.6760 - val_accuracy: 0.0223\n",
            "Epoch 144/600\n",
            "32/32 [==============================] - 15s 459ms/step - loss: 1.1152 - accuracy: 0.0296 - val_loss: 1.6822 - val_accuracy: 0.0223\n",
            "Epoch 145/600\n",
            "32/32 [==============================] - 14s 428ms/step - loss: 1.1152 - accuracy: 0.0289 - val_loss: 1.6926 - val_accuracy: 0.0205\n",
            "Epoch 146/600\n",
            "32/32 [==============================] - 15s 456ms/step - loss: 1.1116 - accuracy: 0.0291 - val_loss: 1.6904 - val_accuracy: 0.0217\n",
            "Epoch 147/600\n",
            "32/32 [==============================] - 15s 474ms/step - loss: 1.1063 - accuracy: 0.0297 - val_loss: 1.6846 - val_accuracy: 0.0210\n",
            "Epoch 148/600\n",
            "32/32 [==============================] - 15s 458ms/step - loss: 1.1077 - accuracy: 0.0292 - val_loss: 1.6928 - val_accuracy: 0.0213\n",
            "Epoch 149/600\n",
            "32/32 [==============================] - 14s 451ms/step - loss: 1.1054 - accuracy: 0.0295 - val_loss: 1.6932 - val_accuracy: 0.0223\n",
            "Epoch 150/600\n",
            "32/32 [==============================] - 15s 459ms/step - loss: 1.1054 - accuracy: 0.0292 - val_loss: 1.6893 - val_accuracy: 0.0210\n",
            "Epoch 151/600\n",
            "32/32 [==============================] - 15s 477ms/step - loss: 1.1073 - accuracy: 0.0292 - val_loss: 1.6963 - val_accuracy: 0.0213\n",
            "Epoch 152/600\n",
            "32/32 [==============================] - 15s 482ms/step - loss: 1.1020 - accuracy: 0.0292 - val_loss: 1.6919 - val_accuracy: 0.0210\n",
            "Epoch 153/600\n",
            "32/32 [==============================] - 15s 483ms/step - loss: 1.0990 - accuracy: 0.0305 - val_loss: 1.7035 - val_accuracy: 0.0207\n",
            "Epoch 154/600\n",
            "32/32 [==============================] - 14s 433ms/step - loss: 1.0957 - accuracy: 0.0301 - val_loss: 1.7104 - val_accuracy: 0.0207\n",
            "Epoch 155/600\n",
            "32/32 [==============================] - 16s 507ms/step - loss: 1.0981 - accuracy: 0.0308 - val_loss: 1.7060 - val_accuracy: 0.0220\n",
            "Epoch 156/600\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.0979 - accuracy: 0.0306 - val_loss: 1.6915 - val_accuracy: 0.0213\n",
            "Epoch 157/600\n",
            "32/32 [==============================] - 16s 498ms/step - loss: 1.0856 - accuracy: 0.0312 - val_loss: 1.6994 - val_accuracy: 0.0205\n",
            "Epoch 158/600\n",
            "32/32 [==============================] - 14s 431ms/step - loss: 1.0969 - accuracy: 0.0309 - val_loss: 1.6936 - val_accuracy: 0.0215\n",
            "Epoch 159/600\n",
            "32/32 [==============================] - 14s 438ms/step - loss: 1.0867 - accuracy: 0.0314 - val_loss: 1.6869 - val_accuracy: 0.0220\n",
            "Epoch 160/600\n",
            "32/32 [==============================] - 15s 455ms/step - loss: 1.0891 - accuracy: 0.0314 - val_loss: 1.6971 - val_accuracy: 0.0220\n",
            "Epoch 161/600\n",
            "32/32 [==============================] - 14s 434ms/step - loss: 1.0897 - accuracy: 0.0312 - val_loss: 1.6984 - val_accuracy: 0.0217\n",
            "Epoch 162/600\n",
            "32/32 [==============================] - 16s 496ms/step - loss: 1.0865 - accuracy: 0.0310 - val_loss: 1.6934 - val_accuracy: 0.0210\n",
            "Epoch 163/600\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 1.0741 - accuracy: 0.0318 - val_loss: 1.7064 - val_accuracy: 0.0223\n",
            "Epoch 164/600\n",
            "32/32 [==============================] - 15s 481ms/step - loss: 1.0797 - accuracy: 0.0319 - val_loss: 1.7094 - val_accuracy: 0.0217\n",
            "Epoch 165/600\n",
            "32/32 [==============================] - 15s 457ms/step - loss: 1.0786 - accuracy: 0.0321 - val_loss: 1.6924 - val_accuracy: 0.0213\n",
            "Epoch 166/600\n",
            "32/32 [==============================] - 17s 520ms/step - loss: 1.0827 - accuracy: 0.0314 - val_loss: 1.6987 - val_accuracy: 0.0215\n",
            "Epoch 167/600\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 1.0860 - accuracy: 0.0310 - val_loss: 1.7008 - val_accuracy: 0.0213\n",
            "Epoch 168/600\n",
            "32/32 [==============================] - 14s 429ms/step - loss: 1.0740 - accuracy: 0.0328 - val_loss: 1.7100 - val_accuracy: 0.0220\n",
            "Epoch 169/600\n",
            "32/32 [==============================] - 15s 459ms/step - loss: 1.0885 - accuracy: 0.0306 - val_loss: 1.6857 - val_accuracy: 0.0210\n",
            "Epoch 170/600\n",
            "32/32 [==============================] - 15s 475ms/step - loss: 1.0805 - accuracy: 0.0315 - val_loss: 1.6996 - val_accuracy: 0.0213\n",
            "Epoch 171/600\n",
            "32/32 [==============================] - 15s 453ms/step - loss: 1.0754 - accuracy: 0.0321 - val_loss: 1.6937 - val_accuracy: 0.0210\n",
            "Epoch 172/600\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 1.0771 - accuracy: 0.0320 - val_loss: 1.6979 - val_accuracy: 0.0220\n",
            "Epoch 173/600\n",
            "32/32 [==============================] - 15s 475ms/step - loss: 1.0764 - accuracy: 0.0321 - val_loss: 1.6874 - val_accuracy: 0.0213\n",
            "Epoch 174/600\n",
            "32/32 [==============================] - 14s 452ms/step - loss: 1.0724 - accuracy: 0.0326 - val_loss: 1.6964 - val_accuracy: 0.0223\n",
            "Epoch 175/600\n",
            "32/32 [==============================] - 15s 458ms/step - loss: 1.0677 - accuracy: 0.0334 - val_loss: 1.7000 - val_accuracy: 0.0225\n",
            "Epoch 176/600\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.0626 - accuracy: 0.0330 - val_loss: 1.6910 - val_accuracy: 0.0223\n",
            "Epoch 177/600\n",
            "32/32 [==============================] - 14s 441ms/step - loss: 1.0673 - accuracy: 0.0331 - val_loss: 1.6931 - val_accuracy: 0.0220\n",
            "Epoch 178/600\n",
            "32/32 [==============================] - 15s 481ms/step - loss: 1.0671 - accuracy: 0.0336 - val_loss: 1.6905 - val_accuracy: 0.0220\n",
            "Epoch 179/600\n",
            "32/32 [==============================] - 16s 501ms/step - loss: 1.0607 - accuracy: 0.0334 - val_loss: 1.6878 - val_accuracy: 0.0215\n",
            "Epoch 180/600\n",
            "32/32 [==============================] - 15s 476ms/step - loss: 1.0602 - accuracy: 0.0327 - val_loss: 1.6888 - val_accuracy: 0.0207\n",
            "Epoch 181/600\n",
            "32/32 [==============================] - 16s 488ms/step - loss: 1.0579 - accuracy: 0.0346 - val_loss: 1.7094 - val_accuracy: 0.0215\n",
            "Epoch 182/600\n",
            "32/32 [==============================] - 15s 456ms/step - loss: 1.0622 - accuracy: 0.0332 - val_loss: 1.6980 - val_accuracy: 0.0215\n",
            "Epoch 183/600\n",
            "32/32 [==============================] - 15s 456ms/step - loss: 1.0938 - accuracy: 0.0320 - val_loss: 1.6762 - val_accuracy: 0.0220\n",
            "Epoch 184/600\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 1.0806 - accuracy: 0.0326 - val_loss: 1.6844 - val_accuracy: 0.0225\n",
            "Epoch 185/600\n",
            "32/32 [==============================] - 14s 433ms/step - loss: 1.0648 - accuracy: 0.0337 - val_loss: 1.6939 - val_accuracy: 0.0225\n",
            "Epoch 186/600\n",
            "32/32 [==============================] - 16s 502ms/step - loss: 1.0550 - accuracy: 0.0349 - val_loss: 1.7042 - val_accuracy: 0.0215\n",
            "Epoch 187/600\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.0526 - accuracy: 0.0340 - val_loss: 1.6934 - val_accuracy: 0.0215\n",
            "Epoch 188/600\n",
            "32/32 [==============================] - 15s 469ms/step - loss: 1.0519 - accuracy: 0.0349 - val_loss: 1.6982 - val_accuracy: 0.0215\n",
            "Epoch 189/600\n",
            "32/32 [==============================] - 15s 458ms/step - loss: 1.0524 - accuracy: 0.0345 - val_loss: 1.7099 - val_accuracy: 0.0213\n",
            "Epoch 190/600\n",
            "32/32 [==============================] - 15s 480ms/step - loss: 1.0489 - accuracy: 0.0351 - val_loss: 1.6978 - val_accuracy: 0.0213\n",
            "Epoch 191/600\n",
            "32/32 [==============================] - 13s 416ms/step - loss: 1.0545 - accuracy: 0.0349 - val_loss: 1.6927 - val_accuracy: 0.0213\n",
            "Epoch 192/600\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 1.0528 - accuracy: 0.0351 - val_loss: 1.6871 - val_accuracy: 0.0217\n",
            "Epoch 193/600\n",
            "32/32 [==============================] - 14s 440ms/step - loss: 1.0628 - accuracy: 0.0340 - val_loss: 1.6935 - val_accuracy: 0.0217\n",
            "Epoch 194/600\n",
            "32/32 [==============================] - 16s 496ms/step - loss: 1.0520 - accuracy: 0.0345 - val_loss: 1.6928 - val_accuracy: 0.0225\n",
            "Epoch 195/600\n",
            "32/32 [==============================] - 15s 462ms/step - loss: 1.0563 - accuracy: 0.0344 - val_loss: 1.6889 - val_accuracy: 0.0210\n",
            "Epoch 196/600\n",
            "32/32 [==============================] - 15s 476ms/step - loss: 1.0566 - accuracy: 0.0341 - val_loss: 1.6989 - val_accuracy: 0.0220\n",
            "Epoch 197/600\n",
            "32/32 [==============================] - 16s 484ms/step - loss: 1.0576 - accuracy: 0.0344 - val_loss: 1.6986 - val_accuracy: 0.0220\n",
            "Epoch 198/600\n",
            "32/32 [==============================] - 15s 454ms/step - loss: 1.0543 - accuracy: 0.0352 - val_loss: 1.6818 - val_accuracy: 0.0215\n",
            "Epoch 199/600\n",
            "32/32 [==============================] - 14s 430ms/step - loss: 1.0526 - accuracy: 0.0356 - val_loss: 1.6846 - val_accuracy: 0.0207\n",
            "Epoch 200/600\n",
            "32/32 [==============================] - 16s 484ms/step - loss: 1.0495 - accuracy: 0.0355 - val_loss: 1.6883 - val_accuracy: 0.0217\n",
            "Epoch 201/600\n",
            "32/32 [==============================] - 15s 483ms/step - loss: 1.0524 - accuracy: 0.0356 - val_loss: 1.6925 - val_accuracy: 0.0225\n",
            "Epoch 202/600\n",
            "32/32 [==============================] - 15s 479ms/step - loss: 1.0448 - accuracy: 0.0355 - val_loss: 1.6990 - val_accuracy: 0.0213\n",
            "Epoch 203/600\n",
            "32/32 [==============================] - 15s 468ms/step - loss: 1.0392 - accuracy: 0.0374 - val_loss: 1.6939 - val_accuracy: 0.0220\n",
            "Epoch 204/600\n",
            "32/32 [==============================] - 16s 499ms/step - loss: 1.0453 - accuracy: 0.0358 - val_loss: 1.7030 - val_accuracy: 0.0220\n",
            "Epoch 205/600\n",
            "32/32 [==============================] - 15s 484ms/step - loss: 1.0336 - accuracy: 0.0371 - val_loss: 1.7097 - val_accuracy: 0.0217\n",
            "Epoch 206/600\n",
            "32/32 [==============================] - 16s 486ms/step - loss: 1.0438 - accuracy: 0.0357 - val_loss: 1.7029 - val_accuracy: 0.0217\n",
            "Epoch 207/600\n",
            "32/32 [==============================] - 15s 484ms/step - loss: 1.0352 - accuracy: 0.0371 - val_loss: 1.7060 - val_accuracy: 0.0225\n",
            "Epoch 208/600\n",
            "32/32 [==============================] - 16s 500ms/step - loss: 1.0280 - accuracy: 0.0378 - val_loss: 1.6998 - val_accuracy: 0.0213\n",
            "Epoch 209/600\n",
            "32/32 [==============================] - 15s 468ms/step - loss: 1.0345 - accuracy: 0.0369 - val_loss: 1.6981 - val_accuracy: 0.0217\n",
            "Epoch 210/600\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.0459 - accuracy: 0.0366 - val_loss: 1.7063 - val_accuracy: 0.0217\n",
            "Epoch 211/600\n",
            "32/32 [==============================] - 16s 492ms/step - loss: 1.0349 - accuracy: 0.0377 - val_loss: 1.7142 - val_accuracy: 0.0215\n",
            "Epoch 212/600\n",
            "32/32 [==============================] - 14s 423ms/step - loss: 1.0663 - accuracy: 0.0334 - val_loss: 1.6958 - val_accuracy: 0.0217\n",
            "Epoch 213/600\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 1.0503 - accuracy: 0.0364 - val_loss: 1.6919 - val_accuracy: 0.0220\n",
            "Epoch 214/600\n",
            "32/32 [==============================] - 15s 475ms/step - loss: 1.0317 - accuracy: 0.0378 - val_loss: 1.7088 - val_accuracy: 0.0215\n",
            "Epoch 215/600\n",
            "32/32 [==============================] - 16s 505ms/step - loss: 1.0263 - accuracy: 0.0378 - val_loss: 1.7037 - val_accuracy: 0.0223\n",
            "Epoch 216/600\n",
            "32/32 [==============================] - 15s 480ms/step - loss: 1.1044 - accuracy: 0.0302 - val_loss: 1.6629 - val_accuracy: 0.0207\n",
            "Epoch 217/600\n",
            "32/32 [==============================] - 14s 435ms/step - loss: 1.1016 - accuracy: 0.0311 - val_loss: 1.6915 - val_accuracy: 0.0215\n",
            "Epoch 218/600\n",
            "32/32 [==============================] - 16s 489ms/step - loss: 1.0626 - accuracy: 0.0342 - val_loss: 1.6989 - val_accuracy: 0.0227\n",
            "Epoch 219/600\n",
            "32/32 [==============================] - 16s 511ms/step - loss: 1.0493 - accuracy: 0.0360 - val_loss: 1.6878 - val_accuracy: 0.0223\n",
            "Epoch 220/600\n",
            "32/32 [==============================] - 15s 456ms/step - loss: 1.0444 - accuracy: 0.0353 - val_loss: 1.7101 - val_accuracy: 0.0220\n",
            "Epoch 221/600\n",
            "32/32 [==============================] - 16s 494ms/step - loss: 1.0446 - accuracy: 0.0360 - val_loss: 1.6896 - val_accuracy: 0.0233\n",
            "Epoch 222/600\n",
            "32/32 [==============================] - 16s 499ms/step - loss: 1.0410 - accuracy: 0.0373 - val_loss: 1.7072 - val_accuracy: 0.0215\n",
            "Epoch 223/600\n",
            "32/32 [==============================] - 16s 488ms/step - loss: 1.0372 - accuracy: 0.0376 - val_loss: 1.7057 - val_accuracy: 0.0220\n",
            "Epoch 224/600\n",
            "32/32 [==============================] - 16s 503ms/step - loss: 1.0275 - accuracy: 0.0384 - val_loss: 1.7084 - val_accuracy: 0.0225\n",
            "Epoch 225/600\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 1.0277 - accuracy: 0.0391 - val_loss: 1.7133 - val_accuracy: 0.0220\n",
            "Epoch 226/600\n",
            "32/32 [==============================] - 14s 430ms/step - loss: 1.0301 - accuracy: 0.0381 - val_loss: 1.6959 - val_accuracy: 0.0227\n",
            "Epoch 227/600\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 1.0336 - accuracy: 0.0385 - val_loss: 1.7021 - val_accuracy: 0.0225\n",
            "Epoch 228/600\n",
            "32/32 [==============================] - 16s 498ms/step - loss: 1.0412 - accuracy: 0.0367 - val_loss: 1.6932 - val_accuracy: 0.0235\n",
            "Epoch 229/600\n",
            "32/32 [==============================] - 15s 476ms/step - loss: 1.0306 - accuracy: 0.0377 - val_loss: 1.7079 - val_accuracy: 0.0217\n",
            "Epoch 230/600\n",
            "32/32 [==============================] - 14s 442ms/step - loss: 1.0257 - accuracy: 0.0389 - val_loss: 1.6923 - val_accuracy: 0.0215\n",
            "Epoch 231/600\n",
            "32/32 [==============================] - 16s 498ms/step - loss: 1.0236 - accuracy: 0.0385 - val_loss: 1.6961 - val_accuracy: 0.0213\n",
            "Epoch 232/600\n",
            "32/32 [==============================] - 15s 478ms/step - loss: 1.0325 - accuracy: 0.0385 - val_loss: 1.7032 - val_accuracy: 0.0213\n",
            "Epoch 233/600\n",
            "32/32 [==============================] - 16s 490ms/step - loss: 1.0208 - accuracy: 0.0394 - val_loss: 1.6960 - val_accuracy: 0.0220\n",
            "Epoch 234/600\n",
            "32/32 [==============================] - 17s 524ms/step - loss: 1.0394 - accuracy: 0.0376 - val_loss: 1.6968 - val_accuracy: 0.0230\n",
            "Epoch 235/600\n",
            "32/32 [==============================] - 17s 518ms/step - loss: 1.0259 - accuracy: 0.0388 - val_loss: 1.7048 - val_accuracy: 0.0233\n",
            "Epoch 236/600\n",
            "32/32 [==============================] - 15s 476ms/step - loss: 1.0188 - accuracy: 0.0399 - val_loss: 1.7015 - val_accuracy: 0.0223\n",
            "Epoch 237/600\n",
            "32/32 [==============================] - 16s 512ms/step - loss: 1.0117 - accuracy: 0.0410 - val_loss: 1.7070 - val_accuracy: 0.0220\n",
            "Epoch 238/600\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 1.0096 - accuracy: 0.0411 - val_loss: 1.7094 - val_accuracy: 0.0220\n",
            "Epoch 239/600\n",
            "32/32 [==============================] - 15s 485ms/step - loss: 1.0086 - accuracy: 0.0408 - val_loss: 1.7028 - val_accuracy: 0.0223\n",
            "Epoch 240/600\n",
            "32/32 [==============================] - 17s 541ms/step - loss: 1.0227 - accuracy: 0.0407 - val_loss: 1.6996 - val_accuracy: 0.0215\n",
            "Epoch 241/600\n",
            "32/32 [==============================] - 15s 478ms/step - loss: 1.0135 - accuracy: 0.0402 - val_loss: 1.6916 - val_accuracy: 0.0217\n",
            "Epoch 242/600\n",
            "32/32 [==============================] - 17s 540ms/step - loss: 0.9997 - accuracy: 0.0438 - val_loss: 1.6998 - val_accuracy: 0.0225\n",
            "Epoch 243/600\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 1.0055 - accuracy: 0.0416 - val_loss: 1.6957 - val_accuracy: 0.0215\n",
            "Epoch 244/600\n",
            "32/32 [==============================] - 15s 484ms/step - loss: 1.0031 - accuracy: 0.0418 - val_loss: 1.7027 - val_accuracy: 0.0220\n",
            "Epoch 245/600\n",
            "32/32 [==============================] - 17s 519ms/step - loss: 1.0108 - accuracy: 0.0407 - val_loss: 1.7139 - val_accuracy: 0.0223\n",
            "Epoch 246/600\n",
            "32/32 [==============================] - 16s 507ms/step - loss: 1.0092 - accuracy: 0.0417 - val_loss: 1.6911 - val_accuracy: 0.0210\n",
            "Epoch 247/600\n",
            "32/32 [==============================] - 16s 495ms/step - loss: 0.9997 - accuracy: 0.0426 - val_loss: 1.6957 - val_accuracy: 0.0220\n",
            "Epoch 248/600\n",
            "32/32 [==============================] - 15s 475ms/step - loss: 0.9999 - accuracy: 0.0426 - val_loss: 1.7069 - val_accuracy: 0.0217\n",
            "Epoch 249/600\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 1.0023 - accuracy: 0.0419 - val_loss: 1.7102 - val_accuracy: 0.0213\n",
            "Epoch 250/600\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 0.9964 - accuracy: 0.0440 - val_loss: 1.7039 - val_accuracy: 0.0227\n",
            "Epoch 251/600\n",
            "32/32 [==============================] - 15s 486ms/step - loss: 0.9987 - accuracy: 0.0432 - val_loss: 1.7045 - val_accuracy: 0.0207\n",
            "Epoch 252/600\n",
            "32/32 [==============================] - 16s 509ms/step - loss: 0.9915 - accuracy: 0.0443 - val_loss: 1.7037 - val_accuracy: 0.0227\n",
            "Epoch 253/600\n",
            "32/32 [==============================] - 15s 480ms/step - loss: 0.9957 - accuracy: 0.0432 - val_loss: 1.6937 - val_accuracy: 0.0217\n",
            "Epoch 254/600\n",
            "32/32 [==============================] - 14s 438ms/step - loss: 1.0121 - accuracy: 0.0426 - val_loss: 1.6989 - val_accuracy: 0.0223\n",
            "Epoch 255/600\n",
            "32/32 [==============================] - 17s 530ms/step - loss: 0.9932 - accuracy: 0.0450 - val_loss: 1.7052 - val_accuracy: 0.0225\n",
            "Epoch 256/600\n",
            "32/32 [==============================] - 16s 494ms/step - loss: 0.9953 - accuracy: 0.0446 - val_loss: 1.6922 - val_accuracy: 0.0223\n",
            "Epoch 257/600\n",
            "32/32 [==============================] - 16s 509ms/step - loss: 0.9917 - accuracy: 0.0439 - val_loss: 1.6901 - val_accuracy: 0.0217\n",
            "Epoch 258/600\n",
            "32/32 [==============================] - 16s 507ms/step - loss: 0.9902 - accuracy: 0.0450 - val_loss: 1.6992 - val_accuracy: 0.0217\n",
            "Epoch 259/600\n",
            "32/32 [==============================] - 16s 487ms/step - loss: 0.9890 - accuracy: 0.0443 - val_loss: 1.6935 - val_accuracy: 0.0223\n",
            "Epoch 260/600\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.9842 - accuracy: 0.0446 - val_loss: 1.6931 - val_accuracy: 0.0227\n",
            "Epoch 261/600\n",
            "32/32 [==============================] - 14s 430ms/step - loss: 0.9783 - accuracy: 0.0470 - val_loss: 1.7030 - val_accuracy: 0.0213\n",
            "Epoch 262/600\n",
            "32/32 [==============================] - 14s 442ms/step - loss: 0.9822 - accuracy: 0.0459 - val_loss: 1.6979 - val_accuracy: 0.0215\n",
            "Epoch 263/600\n",
            "32/32 [==============================] - 15s 471ms/step - loss: 0.9835 - accuracy: 0.0446 - val_loss: 1.6903 - val_accuracy: 0.0220\n",
            "Epoch 264/600\n",
            "32/32 [==============================] - 16s 498ms/step - loss: 0.9815 - accuracy: 0.0458 - val_loss: 1.6948 - val_accuracy: 0.0213\n",
            "Epoch 265/600\n",
            "32/32 [==============================] - 15s 465ms/step - loss: 0.9829 - accuracy: 0.0449 - val_loss: 1.7055 - val_accuracy: 0.0225\n",
            "Epoch 266/600\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 0.9708 - accuracy: 0.0470 - val_loss: 1.6946 - val_accuracy: 0.0215\n",
            "Epoch 267/600\n",
            "32/32 [==============================] - 14s 448ms/step - loss: 0.9693 - accuracy: 0.0469 - val_loss: 1.7049 - val_accuracy: 0.0225\n",
            "Epoch 268/600\n",
            "32/32 [==============================] - 14s 435ms/step - loss: 0.9713 - accuracy: 0.0471 - val_loss: 1.6963 - val_accuracy: 0.0215\n",
            "Epoch 269/600\n",
            "32/32 [==============================] - 14s 440ms/step - loss: 0.9723 - accuracy: 0.0463 - val_loss: 1.6953 - val_accuracy: 0.0217\n",
            "Epoch 270/600\n",
            "32/32 [==============================] - 16s 505ms/step - loss: 0.9747 - accuracy: 0.0474 - val_loss: 1.6961 - val_accuracy: 0.0223\n",
            "Epoch 271/600\n",
            "32/32 [==============================] - 15s 483ms/step - loss: 0.9692 - accuracy: 0.0476 - val_loss: 1.7115 - val_accuracy: 0.0210\n",
            "Epoch 272/600\n",
            "32/32 [==============================] - 16s 493ms/step - loss: 0.9664 - accuracy: 0.0478 - val_loss: 1.6876 - val_accuracy: 0.0203\n",
            "Epoch 273/600\n",
            "32/32 [==============================] - 15s 481ms/step - loss: 0.9686 - accuracy: 0.0479 - val_loss: 1.7082 - val_accuracy: 0.0225\n",
            "Epoch 274/600\n",
            "32/32 [==============================] - 14s 423ms/step - loss: 0.9783 - accuracy: 0.0463 - val_loss: 1.6991 - val_accuracy: 0.0220\n",
            "Epoch 275/600\n",
            "32/32 [==============================] - 15s 480ms/step - loss: 0.9599 - accuracy: 0.0492 - val_loss: 1.6986 - val_accuracy: 0.0227\n",
            "Epoch 276/600\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.9583 - accuracy: 0.0499 - val_loss: 1.6961 - val_accuracy: 0.0225\n",
            "Epoch 277/600\n",
            "32/32 [==============================] - 15s 473ms/step - loss: 0.9635 - accuracy: 0.0475 - val_loss: 1.7108 - val_accuracy: 0.0210\n",
            "Epoch 278/600\n",
            "32/32 [==============================] - 14s 439ms/step - loss: 0.9588 - accuracy: 0.0494 - val_loss: 1.7026 - val_accuracy: 0.0225\n",
            "Epoch 279/600\n",
            "32/32 [==============================] - 16s 492ms/step - loss: 0.9525 - accuracy: 0.0498 - val_loss: 1.7030 - val_accuracy: 0.0217\n",
            "Epoch 280/600\n",
            "32/32 [==============================] - 15s 478ms/step - loss: 0.9530 - accuracy: 0.0501 - val_loss: 1.7028 - val_accuracy: 0.0215\n",
            "Epoch 281/600\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.9598 - accuracy: 0.0492 - val_loss: 1.7030 - val_accuracy: 0.0227\n",
            "Epoch 282/600\n",
            "32/32 [==============================] - 15s 476ms/step - loss: 0.9467 - accuracy: 0.0512 - val_loss: 1.7038 - val_accuracy: 0.0217\n",
            "Epoch 283/600\n",
            "32/32 [==============================] - 14s 438ms/step - loss: 0.9513 - accuracy: 0.0498 - val_loss: 1.7007 - val_accuracy: 0.0227\n",
            "Epoch 284/600\n",
            "32/32 [==============================] - 16s 489ms/step - loss: 0.9585 - accuracy: 0.0491 - val_loss: 1.6963 - val_accuracy: 0.0220\n",
            "Epoch 285/600\n",
            "32/32 [==============================] - 14s 441ms/step - loss: 0.9589 - accuracy: 0.0487 - val_loss: 1.7035 - val_accuracy: 0.0225\n",
            "Epoch 286/600\n",
            "32/32 [==============================] - 16s 515ms/step - loss: 0.9484 - accuracy: 0.0512 - val_loss: 1.7108 - val_accuracy: 0.0203\n",
            "Epoch 287/600\n",
            "32/32 [==============================] - 16s 485ms/step - loss: 0.9462 - accuracy: 0.0511 - val_loss: 1.7034 - val_accuracy: 0.0240\n",
            "Epoch 288/600\n",
            "32/32 [==============================] - 15s 462ms/step - loss: 0.9434 - accuracy: 0.0513 - val_loss: 1.6951 - val_accuracy: 0.0220\n",
            "Epoch 289/600\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 0.9432 - accuracy: 0.0514 - val_loss: 1.7012 - val_accuracy: 0.0210\n",
            "Epoch 290/600\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 0.9488 - accuracy: 0.0509 - val_loss: 1.7013 - val_accuracy: 0.0225\n",
            "Epoch 291/600\n",
            "32/32 [==============================] - 15s 469ms/step - loss: 0.9486 - accuracy: 0.0499 - val_loss: 1.6995 - val_accuracy: 0.0213\n",
            "Epoch 292/600\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.9395 - accuracy: 0.0529 - val_loss: 1.7061 - val_accuracy: 0.0217\n",
            "Epoch 293/600\n",
            "32/32 [==============================] - 14s 425ms/step - loss: 0.9438 - accuracy: 0.0509 - val_loss: 1.7091 - val_accuracy: 0.0225\n",
            "Epoch 294/600\n",
            "32/32 [==============================] - 16s 507ms/step - loss: 0.9422 - accuracy: 0.0520 - val_loss: 1.7181 - val_accuracy: 0.0223\n",
            "Epoch 295/600\n",
            "32/32 [==============================] - 14s 434ms/step - loss: 0.9282 - accuracy: 0.0531 - val_loss: 1.7108 - val_accuracy: 0.0227\n",
            "Epoch 296/600\n",
            "32/32 [==============================] - 15s 478ms/step - loss: 0.9299 - accuracy: 0.0539 - val_loss: 1.7096 - val_accuracy: 0.0223\n",
            "Epoch 297/600\n",
            "32/32 [==============================] - 15s 475ms/step - loss: 0.9306 - accuracy: 0.0524 - val_loss: 1.7185 - val_accuracy: 0.0207\n",
            "Epoch 298/600\n",
            "32/32 [==============================] - 17s 526ms/step - loss: 0.9335 - accuracy: 0.0526 - val_loss: 1.7131 - val_accuracy: 0.0225\n",
            "Epoch 299/600\n",
            "32/32 [==============================] - 16s 497ms/step - loss: 0.9404 - accuracy: 0.0527 - val_loss: 1.6977 - val_accuracy: 0.0220\n",
            "Epoch 300/600\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 0.9378 - accuracy: 0.0525 - val_loss: 1.7115 - val_accuracy: 0.0215\n",
            "Epoch 301/600\n",
            "32/32 [==============================] - 14s 449ms/step - loss: 0.9331 - accuracy: 0.0539 - val_loss: 1.7070 - val_accuracy: 0.0227\n",
            "Epoch 302/600\n",
            "32/32 [==============================] - 14s 432ms/step - loss: 0.9331 - accuracy: 0.0531 - val_loss: 1.7056 - val_accuracy: 0.0213\n",
            "Epoch 303/600\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 0.9284 - accuracy: 0.0536 - val_loss: 1.7176 - val_accuracy: 0.0215\n",
            "Epoch 304/600\n",
            "32/32 [==============================] - 15s 467ms/step - loss: 0.9286 - accuracy: 0.0542 - val_loss: 1.7064 - val_accuracy: 0.0220\n",
            "Epoch 305/600\n",
            "32/32 [==============================] - 16s 486ms/step - loss: 0.9237 - accuracy: 0.0538 - val_loss: 1.7035 - val_accuracy: 0.0225\n",
            "Epoch 306/600\n",
            "32/32 [==============================] - 14s 452ms/step - loss: 0.9266 - accuracy: 0.0534 - val_loss: 1.7129 - val_accuracy: 0.0243\n",
            "Epoch 307/600\n",
            "32/32 [==============================] - 14s 435ms/step - loss: 0.9225 - accuracy: 0.0551 - val_loss: 1.7164 - val_accuracy: 0.0233\n",
            "Epoch 308/600\n",
            "32/32 [==============================] - 14s 451ms/step - loss: 0.9188 - accuracy: 0.0550 - val_loss: 1.7069 - val_accuracy: 0.0237\n",
            "Epoch 309/600\n",
            "32/32 [==============================] - 14s 436ms/step - loss: 0.9203 - accuracy: 0.0549 - val_loss: 1.7109 - val_accuracy: 0.0217\n",
            "Epoch 310/600\n",
            "32/32 [==============================] - 16s 496ms/step - loss: 0.9211 - accuracy: 0.0545 - val_loss: 1.7097 - val_accuracy: 0.0240\n",
            "Epoch 311/600\n",
            "32/32 [==============================] - 14s 443ms/step - loss: 0.9210 - accuracy: 0.0549 - val_loss: 1.7018 - val_accuracy: 0.0235\n",
            "Epoch 312/600\n",
            "32/32 [==============================] - 15s 478ms/step - loss: 0.9232 - accuracy: 0.0554 - val_loss: 1.7118 - val_accuracy: 0.0230\n",
            "Epoch 313/600\n",
            "32/32 [==============================] - 15s 468ms/step - loss: 0.9130 - accuracy: 0.0562 - val_loss: 1.7059 - val_accuracy: 0.0237\n",
            "Epoch 314/600\n",
            "32/32 [==============================] - 15s 468ms/step - loss: 0.9171 - accuracy: 0.0547 - val_loss: 1.6977 - val_accuracy: 0.0237\n",
            "Epoch 315/600\n",
            "32/32 [==============================] - 15s 453ms/step - loss: 0.9126 - accuracy: 0.0567 - val_loss: 1.7018 - val_accuracy: 0.0227\n",
            "Epoch 316/600\n",
            "32/32 [==============================] - 14s 432ms/step - loss: 0.9125 - accuracy: 0.0558 - val_loss: 1.7169 - val_accuracy: 0.0223\n",
            "Epoch 317/600\n",
            "32/32 [==============================] - 15s 473ms/step - loss: 0.9101 - accuracy: 0.0561 - val_loss: 1.7155 - val_accuracy: 0.0227\n",
            "Epoch 318/600\n",
            "32/32 [==============================] - 15s 469ms/step - loss: 0.9126 - accuracy: 0.0565 - val_loss: 1.7079 - val_accuracy: 0.0233\n",
            "Epoch 319/600\n",
            "32/32 [==============================] - 15s 481ms/step - loss: 0.9084 - accuracy: 0.0561 - val_loss: 1.7049 - val_accuracy: 0.0227\n",
            "Epoch 320/600\n",
            "32/32 [==============================] - 15s 479ms/step - loss: 0.9067 - accuracy: 0.0573 - val_loss: 1.7067 - val_accuracy: 0.0223\n",
            "Epoch 321/600\n",
            "32/32 [==============================] - 16s 506ms/step - loss: 0.9122 - accuracy: 0.0548 - val_loss: 1.7091 - val_accuracy: 0.0237\n",
            "Epoch 322/600\n",
            "32/32 [==============================] - 14s 435ms/step - loss: 0.9049 - accuracy: 0.0574 - val_loss: 1.7053 - val_accuracy: 0.0233\n",
            "Epoch 323/600\n",
            "32/32 [==============================] - 15s 484ms/step - loss: 0.9006 - accuracy: 0.0576 - val_loss: 1.7175 - val_accuracy: 0.0227\n",
            "Epoch 324/600\n",
            "32/32 [==============================] - 15s 475ms/step - loss: 0.8983 - accuracy: 0.0574 - val_loss: 1.7118 - val_accuracy: 0.0225\n",
            "Epoch 325/600\n",
            "32/32 [==============================] - 15s 459ms/step - loss: 0.8991 - accuracy: 0.0578 - val_loss: 1.7171 - val_accuracy: 0.0233\n",
            "Epoch 326/600\n",
            "32/32 [==============================] - 14s 429ms/step - loss: 0.9032 - accuracy: 0.0576 - val_loss: 1.7145 - val_accuracy: 0.0225\n",
            "Epoch 327/600\n",
            "32/32 [==============================] - 15s 486ms/step - loss: 0.8968 - accuracy: 0.0584 - val_loss: 1.7138 - val_accuracy: 0.0223\n",
            "Epoch 328/600\n",
            "32/32 [==============================] - 14s 443ms/step - loss: 0.8970 - accuracy: 0.0584 - val_loss: 1.7086 - val_accuracy: 0.0220\n",
            "Epoch 329/600\n",
            "32/32 [==============================] - 15s 479ms/step - loss: 0.9014 - accuracy: 0.0581 - val_loss: 1.7082 - val_accuracy: 0.0220\n",
            "Epoch 330/600\n",
            "32/32 [==============================] - 14s 442ms/step - loss: 0.8982 - accuracy: 0.0576 - val_loss: 1.6940 - val_accuracy: 0.0217\n",
            "Epoch 331/600\n",
            "32/32 [==============================] - 15s 456ms/step - loss: 0.9113 - accuracy: 0.0561 - val_loss: 1.7058 - val_accuracy: 0.0227\n",
            "Epoch 332/600\n",
            "32/32 [==============================] - 14s 437ms/step - loss: 0.8896 - accuracy: 0.0593 - val_loss: 1.7075 - val_accuracy: 0.0235\n",
            "Epoch 333/600\n",
            "32/32 [==============================] - 16s 515ms/step - loss: 0.8881 - accuracy: 0.0593 - val_loss: 1.7140 - val_accuracy: 0.0220\n",
            "Epoch 334/600\n",
            "32/32 [==============================] - 15s 483ms/step - loss: 0.8875 - accuracy: 0.0588 - val_loss: 1.7141 - val_accuracy: 0.0223\n",
            "Epoch 335/600\n",
            "32/32 [==============================] - 15s 482ms/step - loss: 0.8968 - accuracy: 0.0577 - val_loss: 1.7083 - val_accuracy: 0.0227\n",
            "Epoch 336/600\n",
            "32/32 [==============================] - 15s 483ms/step - loss: 0.8819 - accuracy: 0.0619 - val_loss: 1.7186 - val_accuracy: 0.0235\n",
            "Epoch 337/600\n",
            "32/32 [==============================] - 16s 502ms/step - loss: 0.8834 - accuracy: 0.0606 - val_loss: 1.7117 - val_accuracy: 0.0230\n",
            "Epoch 338/600\n",
            "32/32 [==============================] - 16s 505ms/step - loss: 0.8840 - accuracy: 0.0609 - val_loss: 1.7089 - val_accuracy: 0.0225\n",
            "Epoch 339/600\n",
            "32/32 [==============================] - 14s 452ms/step - loss: 0.8852 - accuracy: 0.0596 - val_loss: 1.7143 - val_accuracy: 0.0227\n",
            "Epoch 340/600\n",
            "32/32 [==============================] - 14s 440ms/step - loss: 0.8915 - accuracy: 0.0605 - val_loss: 1.7132 - val_accuracy: 0.0223\n",
            "Epoch 341/600\n",
            "32/32 [==============================] - 15s 476ms/step - loss: 0.8806 - accuracy: 0.0609 - val_loss: 1.7087 - val_accuracy: 0.0223\n",
            "Epoch 342/600\n",
            "32/32 [==============================] - 16s 504ms/step - loss: 0.8808 - accuracy: 0.0604 - val_loss: 1.7016 - val_accuracy: 0.0223\n",
            "Epoch 343/600\n",
            "32/32 [==============================] - 14s 447ms/step - loss: 0.8750 - accuracy: 0.0626 - val_loss: 1.7065 - val_accuracy: 0.0220\n",
            "Epoch 344/600\n",
            "32/32 [==============================] - 15s 482ms/step - loss: 0.8712 - accuracy: 0.0619 - val_loss: 1.7085 - val_accuracy: 0.0233\n",
            "Epoch 345/600\n",
            "32/32 [==============================] - 13s 422ms/step - loss: 0.8983 - accuracy: 0.0576 - val_loss: 1.7119 - val_accuracy: 0.0223\n",
            "Epoch 346/600\n",
            "32/32 [==============================] - 15s 478ms/step - loss: 0.8747 - accuracy: 0.0618 - val_loss: 1.7111 - val_accuracy: 0.0230\n",
            "Epoch 347/600\n",
            "32/32 [==============================] - 14s 437ms/step - loss: 0.8691 - accuracy: 0.0628 - val_loss: 1.7133 - val_accuracy: 0.0233\n",
            "Epoch 348/600\n",
            "32/32 [==============================] - 14s 452ms/step - loss: 0.8712 - accuracy: 0.0619 - val_loss: 1.7235 - val_accuracy: 0.0230\n",
            "Epoch 349/600\n",
            "32/32 [==============================] - 15s 461ms/step - loss: 0.8745 - accuracy: 0.0622 - val_loss: 1.7196 - val_accuracy: 0.0223\n",
            "Epoch 350/600\n",
            "32/32 [==============================] - 15s 473ms/step - loss: 0.8677 - accuracy: 0.0632 - val_loss: 1.7125 - val_accuracy: 0.0230\n",
            "Epoch 351/600\n",
            "32/32 [==============================] - 16s 495ms/step - loss: 0.8774 - accuracy: 0.0614 - val_loss: 1.7107 - val_accuracy: 0.0220\n",
            "Epoch 352/600\n",
            "32/32 [==============================] - 16s 507ms/step - loss: 0.8725 - accuracy: 0.0614 - val_loss: 1.7132 - val_accuracy: 0.0237\n",
            "Epoch 353/600\n",
            "32/32 [==============================] - 15s 474ms/step - loss: 0.8662 - accuracy: 0.0628 - val_loss: 1.7090 - val_accuracy: 0.0227\n",
            "Epoch 354/600\n",
            "32/32 [==============================] - 15s 468ms/step - loss: 0.8656 - accuracy: 0.0641 - val_loss: 1.7160 - val_accuracy: 0.0233\n",
            "Epoch 355/600\n",
            "32/32 [==============================] - 15s 482ms/step - loss: 0.8700 - accuracy: 0.0640 - val_loss: 1.7100 - val_accuracy: 0.0240\n",
            "Epoch 356/600\n",
            "32/32 [==============================] - 17s 524ms/step - loss: 0.8669 - accuracy: 0.0634 - val_loss: 1.7144 - val_accuracy: 0.0233\n",
            "Epoch 357/600\n",
            "32/32 [==============================] - 17s 533ms/step - loss: 0.8546 - accuracy: 0.0653 - val_loss: 1.7040 - val_accuracy: 0.0243\n",
            "Epoch 358/600\n",
            "32/32 [==============================] - 16s 498ms/step - loss: 0.8619 - accuracy: 0.0639 - val_loss: 1.7125 - val_accuracy: 0.0233\n",
            "Epoch 359/600\n",
            "32/32 [==============================] - 15s 457ms/step - loss: 0.8582 - accuracy: 0.0658 - val_loss: 1.7161 - val_accuracy: 0.0225\n",
            "Epoch 360/600\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 0.8575 - accuracy: 0.0635 - val_loss: 1.7147 - val_accuracy: 0.0220\n",
            "Epoch 361/600\n",
            "32/32 [==============================] - 15s 471ms/step - loss: 0.8556 - accuracy: 0.0652 - val_loss: 1.7235 - val_accuracy: 0.0220\n",
            "Epoch 362/600\n",
            "32/32 [==============================] - 14s 453ms/step - loss: 0.8556 - accuracy: 0.0647 - val_loss: 1.7028 - val_accuracy: 0.0217\n",
            "Epoch 363/600\n",
            "32/32 [==============================] - 14s 455ms/step - loss: 0.8518 - accuracy: 0.0659 - val_loss: 1.7175 - val_accuracy: 0.0225\n",
            "Epoch 364/600\n",
            "32/32 [==============================] - 16s 508ms/step - loss: 0.8497 - accuracy: 0.0666 - val_loss: 1.7160 - val_accuracy: 0.0230\n",
            "Epoch 365/600\n",
            "32/32 [==============================] - 15s 475ms/step - loss: 0.8518 - accuracy: 0.0659 - val_loss: 1.7306 - val_accuracy: 0.0217\n",
            "Epoch 366/600\n",
            "32/32 [==============================] - 17s 524ms/step - loss: 0.8583 - accuracy: 0.0650 - val_loss: 1.7086 - val_accuracy: 0.0227\n",
            "Epoch 367/600\n",
            "32/32 [==============================] - 17s 514ms/step - loss: 0.8475 - accuracy: 0.0658 - val_loss: 1.7262 - val_accuracy: 0.0213\n",
            "Epoch 368/600\n",
            "32/32 [==============================] - 15s 451ms/step - loss: 0.8477 - accuracy: 0.0662 - val_loss: 1.7184 - val_accuracy: 0.0230\n",
            "Epoch 369/600\n",
            "32/32 [==============================] - 14s 453ms/step - loss: 0.8470 - accuracy: 0.0671 - val_loss: 1.7057 - val_accuracy: 0.0240\n",
            "Epoch 370/600\n",
            "32/32 [==============================] - 14s 438ms/step - loss: 0.8401 - accuracy: 0.0677 - val_loss: 1.7226 - val_accuracy: 0.0250\n",
            "Epoch 371/600\n",
            "32/32 [==============================] - 15s 468ms/step - loss: 0.9028 - accuracy: 0.0624 - val_loss: 1.7105 - val_accuracy: 0.0230\n",
            "Epoch 372/600\n",
            "32/32 [==============================] - 15s 472ms/step - loss: 0.8771 - accuracy: 0.0634 - val_loss: 1.7065 - val_accuracy: 0.0220\n",
            "Epoch 373/600\n",
            "32/32 [==============================] - 15s 455ms/step - loss: 0.8639 - accuracy: 0.0651 - val_loss: 1.7085 - val_accuracy: 0.0223\n",
            "Epoch 374/600\n",
            "32/32 [==============================] - 16s 485ms/step - loss: 0.8642 - accuracy: 0.0664 - val_loss: 1.7151 - val_accuracy: 0.0215\n",
            "Epoch 375/600\n",
            "32/32 [==============================] - 15s 480ms/step - loss: 0.8648 - accuracy: 0.0651 - val_loss: 1.7153 - val_accuracy: 0.0223\n",
            "Epoch 376/600\n",
            "32/32 [==============================] - 15s 480ms/step - loss: 0.8470 - accuracy: 0.0680 - val_loss: 1.7228 - val_accuracy: 0.0243\n",
            "Epoch 377/600\n",
            "32/32 [==============================] - 15s 472ms/step - loss: 0.8449 - accuracy: 0.0675 - val_loss: 1.7116 - val_accuracy: 0.0240\n",
            "Epoch 378/600\n",
            "32/32 [==============================] - 16s 481ms/step - loss: 0.8431 - accuracy: 0.0669 - val_loss: 1.7113 - val_accuracy: 0.0220\n",
            "Epoch 379/600\n",
            "32/32 [==============================] - 15s 467ms/step - loss: 0.8406 - accuracy: 0.0681 - val_loss: 1.7250 - val_accuracy: 0.0233\n",
            "Epoch 380/600\n",
            "32/32 [==============================] - 15s 467ms/step - loss: 0.8414 - accuracy: 0.0674 - val_loss: 1.7235 - val_accuracy: 0.0250\n",
            "Epoch 381/600\n",
            "32/32 [==============================] - 15s 469ms/step - loss: 0.8367 - accuracy: 0.0677 - val_loss: 1.7205 - val_accuracy: 0.0235\n",
            "Epoch 382/600\n",
            "32/32 [==============================] - 15s 475ms/step - loss: 0.8329 - accuracy: 0.0692 - val_loss: 1.7151 - val_accuracy: 0.0233\n",
            "Epoch 383/600\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.8301 - accuracy: 0.0689 - val_loss: 1.7163 - val_accuracy: 0.0217\n",
            "Epoch 384/600\n",
            "32/32 [==============================] - 15s 467ms/step - loss: 0.8225 - accuracy: 0.0709 - val_loss: 1.7294 - val_accuracy: 0.0215\n",
            "Epoch 385/600\n",
            "32/32 [==============================] - 16s 495ms/step - loss: 0.8222 - accuracy: 0.0704 - val_loss: 1.7286 - val_accuracy: 0.0233\n",
            "Epoch 386/600\n",
            "32/32 [==============================] - 16s 517ms/step - loss: 0.8240 - accuracy: 0.0699 - val_loss: 1.7193 - val_accuracy: 0.0233\n",
            "Epoch 387/600\n",
            "32/32 [==============================] - 16s 503ms/step - loss: 0.8236 - accuracy: 0.0694 - val_loss: 1.7331 - val_accuracy: 0.0223\n",
            "Epoch 388/600\n",
            "32/32 [==============================] - 17s 542ms/step - loss: 0.8212 - accuracy: 0.0714 - val_loss: 1.7166 - val_accuracy: 0.0223\n",
            "Epoch 389/600\n",
            "32/32 [==============================] - 15s 468ms/step - loss: 0.8214 - accuracy: 0.0704 - val_loss: 1.7329 - val_accuracy: 0.0230\n",
            "Epoch 390/600\n",
            "32/32 [==============================] - 15s 486ms/step - loss: 0.8215 - accuracy: 0.0702 - val_loss: 1.7253 - val_accuracy: 0.0220\n",
            "Epoch 391/600\n",
            "32/32 [==============================] - 16s 491ms/step - loss: 0.8322 - accuracy: 0.0688 - val_loss: 1.7276 - val_accuracy: 0.0215\n",
            "Epoch 392/600\n",
            "32/32 [==============================] - 16s 489ms/step - loss: 0.8129 - accuracy: 0.0721 - val_loss: 1.7213 - val_accuracy: 0.0227\n",
            "Epoch 393/600\n",
            "32/32 [==============================] - 16s 505ms/step - loss: 0.8184 - accuracy: 0.0707 - val_loss: 1.7190 - val_accuracy: 0.0220\n",
            "Epoch 394/600\n",
            "32/32 [==============================] - 16s 516ms/step - loss: 0.8177 - accuracy: 0.0718 - val_loss: 1.7212 - val_accuracy: 0.0235\n",
            "Epoch 395/600\n",
            "32/32 [==============================] - 14s 446ms/step - loss: 0.8116 - accuracy: 0.0725 - val_loss: 1.7220 - val_accuracy: 0.0213\n",
            "Epoch 396/600\n",
            "32/32 [==============================] - 16s 494ms/step - loss: 0.8121 - accuracy: 0.0714 - val_loss: 1.7252 - val_accuracy: 0.0225\n",
            "Epoch 397/600\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 0.8124 - accuracy: 0.0716 - val_loss: 1.7237 - val_accuracy: 0.0233\n",
            "Epoch 398/600\n",
            "32/32 [==============================] - 15s 471ms/step - loss: 0.8079 - accuracy: 0.0723 - val_loss: 1.7196 - val_accuracy: 0.0227\n",
            "Epoch 399/600\n",
            "32/32 [==============================] - 16s 510ms/step - loss: 0.8103 - accuracy: 0.0723 - val_loss: 1.7356 - val_accuracy: 0.0233\n",
            "Epoch 400/600\n",
            "32/32 [==============================] - 15s 456ms/step - loss: 0.8097 - accuracy: 0.0720 - val_loss: 1.7186 - val_accuracy: 0.0223\n",
            "Epoch 401/600\n",
            "32/32 [==============================] - 15s 471ms/step - loss: 0.8073 - accuracy: 0.0730 - val_loss: 1.7246 - val_accuracy: 0.0223\n",
            "Epoch 402/600\n",
            "32/32 [==============================] - 16s 488ms/step - loss: 0.8014 - accuracy: 0.0736 - val_loss: 1.7237 - val_accuracy: 0.0237\n",
            "Epoch 403/600\n",
            "32/32 [==============================] - 15s 452ms/step - loss: 0.8027 - accuracy: 0.0736 - val_loss: 1.7295 - val_accuracy: 0.0223\n",
            "Epoch 404/600\n",
            "32/32 [==============================] - 16s 494ms/step - loss: 0.8036 - accuracy: 0.0746 - val_loss: 1.7266 - val_accuracy: 0.0220\n",
            "Epoch 405/600\n",
            "32/32 [==============================] - 14s 455ms/step - loss: 0.8052 - accuracy: 0.0737 - val_loss: 1.7132 - val_accuracy: 0.0233\n",
            "Epoch 406/600\n",
            "32/32 [==============================] - 16s 489ms/step - loss: 0.7979 - accuracy: 0.0735 - val_loss: 1.7261 - val_accuracy: 0.0230\n",
            "Epoch 407/600\n",
            "32/32 [==============================] - 16s 502ms/step - loss: 0.7976 - accuracy: 0.0744 - val_loss: 1.7424 - val_accuracy: 0.0230\n",
            "Epoch 408/600\n",
            "32/32 [==============================] - 15s 482ms/step - loss: 0.8085 - accuracy: 0.0737 - val_loss: 1.7129 - val_accuracy: 0.0227\n",
            "Epoch 409/600\n",
            "32/32 [==============================] - 15s 487ms/step - loss: 0.8065 - accuracy: 0.0735 - val_loss: 1.7234 - val_accuracy: 0.0227\n",
            "Epoch 410/600\n",
            "32/32 [==============================] - 17s 539ms/step - loss: 0.7961 - accuracy: 0.0752 - val_loss: 1.7195 - val_accuracy: 0.0227\n",
            "Epoch 411/600\n",
            "32/32 [==============================] - 16s 486ms/step - loss: 0.7921 - accuracy: 0.0763 - val_loss: 1.7207 - val_accuracy: 0.0235\n",
            "Epoch 412/600\n",
            "32/32 [==============================] - 16s 488ms/step - loss: 0.7963 - accuracy: 0.0761 - val_loss: 1.7204 - val_accuracy: 0.0230\n",
            "Epoch 413/600\n",
            "32/32 [==============================] - 15s 470ms/step - loss: 0.8053 - accuracy: 0.0729 - val_loss: 1.7240 - val_accuracy: 0.0223\n",
            "Epoch 414/600\n",
            "32/32 [==============================] - 16s 490ms/step - loss: 0.8031 - accuracy: 0.0741 - val_loss: 1.7226 - val_accuracy: 0.0217\n",
            "Epoch 415/600\n",
            "32/32 [==============================] - 16s 513ms/step - loss: 0.8083 - accuracy: 0.0729 - val_loss: 1.7193 - val_accuracy: 0.0223\n",
            "Epoch 416/600\n",
            "32/32 [==============================] - 16s 496ms/step - loss: 0.8138 - accuracy: 0.0717 - val_loss: 1.7059 - val_accuracy: 0.0220\n",
            "Epoch 417/600\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 0.8151 - accuracy: 0.0726 - val_loss: 1.6981 - val_accuracy: 0.0227\n",
            "Epoch 418/600\n",
            "32/32 [==============================] - 15s 477ms/step - loss: 0.8060 - accuracy: 0.0739 - val_loss: 1.7167 - val_accuracy: 0.0217\n",
            "Epoch 419/600\n",
            "32/32 [==============================] - 16s 494ms/step - loss: 0.8085 - accuracy: 0.0725 - val_loss: 1.7062 - val_accuracy: 0.0215\n",
            "Epoch 420/600\n",
            "32/32 [==============================] - 17s 527ms/step - loss: 0.8417 - accuracy: 0.0679 - val_loss: 1.7052 - val_accuracy: 0.0215\n",
            "Epoch 421/600\n",
            "32/32 [==============================] - 16s 515ms/step - loss: 0.8060 - accuracy: 0.0731 - val_loss: 1.7055 - val_accuracy: 0.0215\n",
            "Epoch 422/600\n",
            "32/32 [==============================] - 16s 489ms/step - loss: 0.8116 - accuracy: 0.0723 - val_loss: 1.7182 - val_accuracy: 0.0207\n",
            "Epoch 423/600\n",
            "32/32 [==============================] - 14s 443ms/step - loss: 0.8081 - accuracy: 0.0732 - val_loss: 1.7178 - val_accuracy: 0.0205\n",
            "Epoch 424/600\n",
            "32/32 [==============================] - 17s 532ms/step - loss: 0.8036 - accuracy: 0.0739 - val_loss: 1.7174 - val_accuracy: 0.0205\n",
            "Epoch 425/600\n",
            "32/32 [==============================] - 16s 489ms/step - loss: 0.8346 - accuracy: 0.0714 - val_loss: 1.6849 - val_accuracy: 0.0205\n",
            "Epoch 426/600\n",
            "32/32 [==============================] - 16s 512ms/step - loss: 0.8632 - accuracy: 0.0674 - val_loss: 1.6891 - val_accuracy: 0.0217\n",
            "Epoch 427/600\n",
            "32/32 [==============================] - 15s 484ms/step - loss: 0.8272 - accuracy: 0.0707 - val_loss: 1.6843 - val_accuracy: 0.0220\n",
            "Epoch 428/600\n",
            "32/32 [==============================] - 16s 495ms/step - loss: 0.8488 - accuracy: 0.0684 - val_loss: 1.6980 - val_accuracy: 0.0223\n",
            "Epoch 429/600\n",
            "32/32 [==============================] - 15s 478ms/step - loss: 0.8157 - accuracy: 0.0716 - val_loss: 1.6982 - val_accuracy: 0.0215\n",
            "Epoch 430/600\n",
            "32/32 [==============================] - 16s 494ms/step - loss: 0.7953 - accuracy: 0.0751 - val_loss: 1.6979 - val_accuracy: 0.0205\n",
            "Epoch 431/600\n",
            "32/32 [==============================] - 16s 518ms/step - loss: 0.8005 - accuracy: 0.0751 - val_loss: 1.6972 - val_accuracy: 0.0223\n",
            "Epoch 432/600\n",
            "32/32 [==============================] - 17s 520ms/step - loss: 0.8168 - accuracy: 0.0721 - val_loss: 1.7157 - val_accuracy: 0.0220\n",
            "Epoch 433/600\n",
            "32/32 [==============================] - 15s 487ms/step - loss: 0.7999 - accuracy: 0.0752 - val_loss: 1.6954 - val_accuracy: 0.0210\n",
            "Epoch 434/600\n",
            "32/32 [==============================] - 16s 485ms/step - loss: 0.8168 - accuracy: 0.0720 - val_loss: 1.7128 - val_accuracy: 0.0225\n",
            "Epoch 435/600\n",
            "32/32 [==============================] - 15s 475ms/step - loss: 0.7998 - accuracy: 0.0748 - val_loss: 1.7174 - val_accuracy: 0.0217\n",
            "Epoch 436/600\n",
            "32/32 [==============================] - 15s 470ms/step - loss: 0.8141 - accuracy: 0.0723 - val_loss: 1.7194 - val_accuracy: 0.0217\n",
            "Epoch 437/600\n",
            "32/32 [==============================] - 14s 444ms/step - loss: 0.8130 - accuracy: 0.0732 - val_loss: 1.7195 - val_accuracy: 0.0225\n",
            "Epoch 438/600\n",
            "32/32 [==============================] - 15s 478ms/step - loss: 0.8040 - accuracy: 0.0744 - val_loss: 1.7184 - val_accuracy: 0.0205\n",
            "Epoch 439/600\n",
            "32/32 [==============================] - 15s 485ms/step - loss: 0.7993 - accuracy: 0.0746 - val_loss: 1.6998 - val_accuracy: 0.0220\n",
            "Epoch 440/600\n",
            "32/32 [==============================] - 16s 485ms/step - loss: 0.7926 - accuracy: 0.0764 - val_loss: 1.7180 - val_accuracy: 0.0210\n",
            "Epoch 441/600\n",
            "32/32 [==============================] - 16s 499ms/step - loss: 0.7922 - accuracy: 0.0755 - val_loss: 1.7091 - val_accuracy: 0.0215\n",
            "Epoch 442/600\n",
            "32/32 [==============================] - 15s 472ms/step - loss: 0.7882 - accuracy: 0.0754 - val_loss: 1.7171 - val_accuracy: 0.0217\n",
            "Epoch 443/600\n",
            "32/32 [==============================] - 16s 511ms/step - loss: 0.7821 - accuracy: 0.0769 - val_loss: 1.7169 - val_accuracy: 0.0227\n",
            "Epoch 444/600\n",
            "32/32 [==============================] - 15s 476ms/step - loss: 0.7806 - accuracy: 0.0774 - val_loss: 1.7276 - val_accuracy: 0.0225\n",
            "Epoch 445/600\n",
            "32/32 [==============================] - 17s 522ms/step - loss: 0.7771 - accuracy: 0.0782 - val_loss: 1.7241 - val_accuracy: 0.0217\n",
            "Epoch 446/600\n",
            "32/32 [==============================] - 16s 498ms/step - loss: 0.8037 - accuracy: 0.0735 - val_loss: 1.7203 - val_accuracy: 0.0207\n",
            "Epoch 447/600\n",
            "32/32 [==============================] - 16s 498ms/step - loss: 0.7726 - accuracy: 0.0791 - val_loss: 1.7356 - val_accuracy: 0.0207\n",
            "Epoch 448/600\n",
            "32/32 [==============================] - 16s 493ms/step - loss: 0.7796 - accuracy: 0.0774 - val_loss: 1.7149 - val_accuracy: 0.0210\n",
            "Epoch 449/600\n",
            "32/32 [==============================] - 15s 467ms/step - loss: 0.7805 - accuracy: 0.0781 - val_loss: 1.7198 - val_accuracy: 0.0210\n",
            "Epoch 450/600\n",
            "32/32 [==============================] - 16s 501ms/step - loss: 0.7700 - accuracy: 0.0804 - val_loss: 1.7314 - val_accuracy: 0.0215\n",
            "Epoch 451/600\n",
            "32/32 [==============================] - 15s 475ms/step - loss: 0.7668 - accuracy: 0.0794 - val_loss: 1.7277 - val_accuracy: 0.0223\n",
            "Epoch 452/600\n",
            "32/32 [==============================] - 16s 504ms/step - loss: 0.7673 - accuracy: 0.0801 - val_loss: 1.7178 - val_accuracy: 0.0203\n",
            "Epoch 453/600\n",
            "32/32 [==============================] - 16s 498ms/step - loss: 0.7611 - accuracy: 0.0812 - val_loss: 1.7111 - val_accuracy: 0.0220\n",
            "Epoch 454/600\n",
            "32/32 [==============================] - 16s 496ms/step - loss: 0.7602 - accuracy: 0.0805 - val_loss: 1.7459 - val_accuracy: 0.0220\n",
            "Epoch 455/600\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 0.7699 - accuracy: 0.0791 - val_loss: 1.7128 - val_accuracy: 0.0227\n",
            "Epoch 456/600\n",
            "32/32 [==============================] - 15s 476ms/step - loss: 0.7573 - accuracy: 0.0810 - val_loss: 1.7289 - val_accuracy: 0.0215\n",
            "Epoch 457/600\n",
            "32/32 [==============================] - 16s 488ms/step - loss: 0.7579 - accuracy: 0.0810 - val_loss: 1.7155 - val_accuracy: 0.0217\n",
            "Epoch 458/600\n",
            "32/32 [==============================] - 15s 467ms/step - loss: 0.7654 - accuracy: 0.0791 - val_loss: 1.7416 - val_accuracy: 0.0207\n",
            "Epoch 459/600\n",
            "32/32 [==============================] - 15s 485ms/step - loss: 0.7610 - accuracy: 0.0803 - val_loss: 1.7168 - val_accuracy: 0.0213\n",
            "Epoch 460/600\n",
            "32/32 [==============================] - 15s 471ms/step - loss: 0.7613 - accuracy: 0.0811 - val_loss: 1.7323 - val_accuracy: 0.0205\n",
            "Epoch 461/600\n",
            "32/32 [==============================] - 15s 467ms/step - loss: 0.7606 - accuracy: 0.0808 - val_loss: 1.7287 - val_accuracy: 0.0215\n",
            "Epoch 462/600\n",
            "32/32 [==============================] - 18s 554ms/step - loss: 0.7659 - accuracy: 0.0811 - val_loss: 1.7423 - val_accuracy: 0.0215\n",
            "Epoch 463/600\n",
            "32/32 [==============================] - 15s 482ms/step - loss: 0.7481 - accuracy: 0.0829 - val_loss: 1.7482 - val_accuracy: 0.0210\n",
            "Epoch 464/600\n",
            "32/32 [==============================] - 15s 478ms/step - loss: 0.7553 - accuracy: 0.0821 - val_loss: 1.7393 - val_accuracy: 0.0217\n",
            "Epoch 465/600\n",
            "32/32 [==============================] - 15s 473ms/step - loss: 0.7508 - accuracy: 0.0829 - val_loss: 1.7313 - val_accuracy: 0.0220\n",
            "Epoch 466/600\n",
            "32/32 [==============================] - 16s 503ms/step - loss: 0.7776 - accuracy: 0.0777 - val_loss: 1.7347 - val_accuracy: 0.0205\n",
            "Epoch 467/600\n",
            "32/32 [==============================] - 16s 490ms/step - loss: 0.7689 - accuracy: 0.0790 - val_loss: 1.7428 - val_accuracy: 0.0210\n",
            "Epoch 468/600\n",
            "32/32 [==============================] - 15s 453ms/step - loss: 0.7487 - accuracy: 0.0838 - val_loss: 1.7455 - val_accuracy: 0.0220\n",
            "Epoch 469/600\n",
            "32/32 [==============================] - 16s 491ms/step - loss: 0.7575 - accuracy: 0.0821 - val_loss: 1.7346 - val_accuracy: 0.0213\n",
            "Epoch 470/600\n",
            "32/32 [==============================] - 16s 500ms/step - loss: 0.7517 - accuracy: 0.0824 - val_loss: 1.7255 - val_accuracy: 0.0223\n",
            "Epoch 471/600\n",
            "32/32 [==============================] - 16s 492ms/step - loss: 0.7479 - accuracy: 0.0828 - val_loss: 1.7239 - val_accuracy: 0.0213\n",
            "Epoch 472/600\n",
            "32/32 [==============================] - 15s 482ms/step - loss: 0.7459 - accuracy: 0.0844 - val_loss: 1.7372 - val_accuracy: 0.0223\n",
            "Epoch 473/600\n",
            "32/32 [==============================] - 18s 565ms/step - loss: 0.7588 - accuracy: 0.0811 - val_loss: 1.7219 - val_accuracy: 0.0235\n",
            "Epoch 474/600\n",
            "32/32 [==============================] - 17s 539ms/step - loss: 0.8006 - accuracy: 0.0758 - val_loss: 1.7226 - val_accuracy: 0.0220\n",
            "Epoch 475/600\n",
            "32/32 [==============================] - 16s 516ms/step - loss: 0.7509 - accuracy: 0.0833 - val_loss: 1.7322 - val_accuracy: 0.0220\n",
            "Epoch 476/600\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 0.7561 - accuracy: 0.0814 - val_loss: 1.7227 - val_accuracy: 0.0225\n",
            "Epoch 477/600\n",
            "32/32 [==============================] - 16s 516ms/step - loss: 0.7509 - accuracy: 0.0825 - val_loss: 1.7267 - val_accuracy: 0.0223\n",
            "Epoch 478/600\n",
            "32/32 [==============================] - 16s 494ms/step - loss: 0.7433 - accuracy: 0.0844 - val_loss: 1.7260 - val_accuracy: 0.0220\n",
            "Epoch 479/600\n",
            "32/32 [==============================] - 15s 472ms/step - loss: 0.7604 - accuracy: 0.0821 - val_loss: 1.7318 - val_accuracy: 0.0235\n",
            "Epoch 480/600\n",
            "32/32 [==============================] - 16s 513ms/step - loss: 0.7700 - accuracy: 0.0796 - val_loss: 1.7313 - val_accuracy: 0.0215\n",
            "Epoch 481/600\n",
            "32/32 [==============================] - 17s 515ms/step - loss: 0.7528 - accuracy: 0.0818 - val_loss: 1.7264 - val_accuracy: 0.0217\n",
            "Epoch 482/600\n",
            "32/32 [==============================] - 17s 544ms/step - loss: 0.7398 - accuracy: 0.0851 - val_loss: 1.7369 - val_accuracy: 0.0223\n",
            "Epoch 483/600\n",
            "32/32 [==============================] - 16s 491ms/step - loss: 0.7357 - accuracy: 0.0851 - val_loss: 1.7255 - val_accuracy: 0.0220\n",
            "Epoch 484/600\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 0.7425 - accuracy: 0.0843 - val_loss: 1.7355 - val_accuracy: 0.0213\n",
            "Epoch 485/600\n",
            "32/32 [==============================] - 16s 509ms/step - loss: 0.7383 - accuracy: 0.0844 - val_loss: 1.7229 - val_accuracy: 0.0215\n",
            "Epoch 486/600\n",
            "32/32 [==============================] - 15s 457ms/step - loss: 0.7333 - accuracy: 0.0854 - val_loss: 1.7202 - val_accuracy: 0.0220\n",
            "Epoch 487/600\n",
            "32/32 [==============================] - 17s 539ms/step - loss: 0.7310 - accuracy: 0.0856 - val_loss: 1.7255 - val_accuracy: 0.0215\n",
            "Epoch 488/600\n",
            "32/32 [==============================] - 16s 511ms/step - loss: 0.7389 - accuracy: 0.0844 - val_loss: 1.7421 - val_accuracy: 0.0217\n",
            "Epoch 489/600\n",
            "32/32 [==============================] - 15s 476ms/step - loss: 0.7347 - accuracy: 0.0846 - val_loss: 1.7397 - val_accuracy: 0.0203\n",
            "Epoch 490/600\n",
            "32/32 [==============================] - 16s 497ms/step - loss: 0.7250 - accuracy: 0.0869 - val_loss: 1.7393 - val_accuracy: 0.0210\n",
            "Epoch 491/600\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 0.7201 - accuracy: 0.0878 - val_loss: 1.7361 - val_accuracy: 0.0227\n",
            "Epoch 492/600\n",
            "32/32 [==============================] - 15s 478ms/step - loss: 0.7319 - accuracy: 0.0858 - val_loss: 1.7396 - val_accuracy: 0.0215\n",
            "Epoch 493/600\n",
            "32/32 [==============================] - 16s 515ms/step - loss: 0.7297 - accuracy: 0.0866 - val_loss: 1.7340 - val_accuracy: 0.0213\n",
            "Epoch 494/600\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 0.7373 - accuracy: 0.0844 - val_loss: 1.7327 - val_accuracy: 0.0225\n",
            "Epoch 495/600\n",
            "32/32 [==============================] - 15s 463ms/step - loss: 0.7202 - accuracy: 0.0878 - val_loss: 1.7304 - val_accuracy: 0.0220\n",
            "Epoch 496/600\n",
            "32/32 [==============================] - 17s 536ms/step - loss: 0.7306 - accuracy: 0.0857 - val_loss: 1.7302 - val_accuracy: 0.0215\n",
            "Epoch 497/600\n",
            "32/32 [==============================] - 16s 488ms/step - loss: 0.7262 - accuracy: 0.0866 - val_loss: 1.7370 - val_accuracy: 0.0215\n",
            "Epoch 498/600\n",
            "32/32 [==============================] - 16s 487ms/step - loss: 0.7250 - accuracy: 0.0873 - val_loss: 1.7398 - val_accuracy: 0.0217\n",
            "Epoch 499/600\n",
            "32/32 [==============================] - 17s 521ms/step - loss: 0.7261 - accuracy: 0.0856 - val_loss: 1.7253 - val_accuracy: 0.0225\n",
            "Epoch 500/600\n",
            "32/32 [==============================] - 16s 504ms/step - loss: 0.7136 - accuracy: 0.0893 - val_loss: 1.7384 - val_accuracy: 0.0217\n",
            "Epoch 501/600\n",
            "32/32 [==============================] - 16s 485ms/step - loss: 0.7325 - accuracy: 0.0846 - val_loss: 1.7310 - val_accuracy: 0.0220\n",
            "Epoch 502/600\n",
            "32/32 [==============================] - 17s 550ms/step - loss: 0.7178 - accuracy: 0.0879 - val_loss: 1.7334 - val_accuracy: 0.0205\n",
            "Epoch 503/600\n",
            "32/32 [==============================] - 16s 502ms/step - loss: 0.7140 - accuracy: 0.0894 - val_loss: 1.7331 - val_accuracy: 0.0213\n",
            "Epoch 504/600\n",
            "32/32 [==============================] - 15s 478ms/step - loss: 0.7221 - accuracy: 0.0879 - val_loss: 1.7318 - val_accuracy: 0.0210\n",
            "Epoch 505/600\n",
            "32/32 [==============================] - 16s 516ms/step - loss: 0.7163 - accuracy: 0.0876 - val_loss: 1.7345 - val_accuracy: 0.0213\n",
            "Epoch 506/600\n",
            "32/32 [==============================] - 18s 554ms/step - loss: 0.7205 - accuracy: 0.0876 - val_loss: 1.7308 - val_accuracy: 0.0217\n",
            "Epoch 507/600\n",
            "32/32 [==============================] - 17s 531ms/step - loss: 0.7154 - accuracy: 0.0903 - val_loss: 1.7469 - val_accuracy: 0.0223\n",
            "Epoch 508/600\n",
            "32/32 [==============================] - 17s 518ms/step - loss: 0.7075 - accuracy: 0.0891 - val_loss: 1.7324 - val_accuracy: 0.0225\n",
            "Epoch 509/600\n",
            "32/32 [==============================] - 15s 482ms/step - loss: 0.6996 - accuracy: 0.0921 - val_loss: 1.7419 - val_accuracy: 0.0217\n",
            "Epoch 510/600\n",
            "32/32 [==============================] - 18s 554ms/step - loss: 0.6954 - accuracy: 0.0922 - val_loss: 1.7321 - val_accuracy: 0.0233\n",
            "Epoch 511/600\n",
            "32/32 [==============================] - 17s 527ms/step - loss: 0.7118 - accuracy: 0.0892 - val_loss: 1.7242 - val_accuracy: 0.0227\n",
            "Epoch 512/600\n",
            "32/32 [==============================] - 18s 577ms/step - loss: 0.6980 - accuracy: 0.0915 - val_loss: 1.7241 - val_accuracy: 0.0225\n",
            "Epoch 513/600\n",
            "32/32 [==============================] - 16s 494ms/step - loss: 0.6993 - accuracy: 0.0919 - val_loss: 1.7296 - val_accuracy: 0.0220\n",
            "Epoch 514/600\n",
            "32/32 [==============================] - 16s 518ms/step - loss: 0.7121 - accuracy: 0.0884 - val_loss: 1.7476 - val_accuracy: 0.0223\n",
            "Epoch 515/600\n",
            "32/32 [==============================] - 16s 511ms/step - loss: 0.7124 - accuracy: 0.0879 - val_loss: 1.7209 - val_accuracy: 0.0213\n",
            "Epoch 516/600\n",
            "32/32 [==============================] - 16s 498ms/step - loss: 0.7067 - accuracy: 0.0900 - val_loss: 1.7445 - val_accuracy: 0.0205\n",
            "Epoch 517/600\n",
            "32/32 [==============================] - 17s 543ms/step - loss: 0.7084 - accuracy: 0.0901 - val_loss: 1.7428 - val_accuracy: 0.0217\n",
            "Epoch 518/600\n",
            "32/32 [==============================] - 18s 550ms/step - loss: 0.7003 - accuracy: 0.0902 - val_loss: 1.7325 - val_accuracy: 0.0220\n",
            "Epoch 519/600\n",
            "32/32 [==============================] - 17s 517ms/step - loss: 0.6987 - accuracy: 0.0921 - val_loss: 1.7339 - val_accuracy: 0.0210\n",
            "Epoch 520/600\n",
            "32/32 [==============================] - 17s 548ms/step - loss: 0.7064 - accuracy: 0.0903 - val_loss: 1.7412 - val_accuracy: 0.0220\n",
            "Epoch 521/600\n",
            "32/32 [==============================] - 18s 556ms/step - loss: 0.7060 - accuracy: 0.0899 - val_loss: 1.7600 - val_accuracy: 0.0207\n",
            "Epoch 522/600\n",
            "32/32 [==============================] - 16s 509ms/step - loss: 0.6947 - accuracy: 0.0919 - val_loss: 1.7376 - val_accuracy: 0.0227\n",
            "Epoch 523/600\n",
            "32/32 [==============================] - 16s 497ms/step - loss: 0.6906 - accuracy: 0.0921 - val_loss: 1.7491 - val_accuracy: 0.0207\n",
            "Epoch 524/600\n",
            "32/32 [==============================] - 15s 481ms/step - loss: 0.7036 - accuracy: 0.0911 - val_loss: 1.7440 - val_accuracy: 0.0223\n",
            "Epoch 525/600\n",
            "32/32 [==============================] - 16s 495ms/step - loss: 0.6916 - accuracy: 0.0931 - val_loss: 1.7470 - val_accuracy: 0.0210\n",
            "Epoch 526/600\n",
            "32/32 [==============================] - 17s 523ms/step - loss: 0.6878 - accuracy: 0.0940 - val_loss: 1.7373 - val_accuracy: 0.0205\n",
            "Epoch 527/600\n",
            "32/32 [==============================] - 17s 527ms/step - loss: 0.6905 - accuracy: 0.0926 - val_loss: 1.7387 - val_accuracy: 0.0215\n",
            "Epoch 528/600\n",
            "32/32 [==============================] - 16s 499ms/step - loss: 0.6910 - accuracy: 0.0926 - val_loss: 1.7445 - val_accuracy: 0.0207\n",
            "Epoch 529/600\n",
            "32/32 [==============================] - 17s 522ms/step - loss: 0.6902 - accuracy: 0.0931 - val_loss: 1.7413 - val_accuracy: 0.0215\n",
            "Epoch 530/600\n",
            "32/32 [==============================] - 15s 477ms/step - loss: 0.6862 - accuracy: 0.0945 - val_loss: 1.7344 - val_accuracy: 0.0213\n",
            "Epoch 531/600\n",
            "32/32 [==============================] - 18s 578ms/step - loss: 0.6875 - accuracy: 0.0933 - val_loss: 1.7596 - val_accuracy: 0.0207\n",
            "Epoch 532/600\n",
            "32/32 [==============================] - 16s 500ms/step - loss: 0.6856 - accuracy: 0.0935 - val_loss: 1.7509 - val_accuracy: 0.0207\n",
            "Epoch 533/600\n",
            "32/32 [==============================] - 15s 473ms/step - loss: 0.6905 - accuracy: 0.0918 - val_loss: 1.7211 - val_accuracy: 0.0215\n",
            "Epoch 534/600\n",
            "32/32 [==============================] - 16s 492ms/step - loss: 0.6898 - accuracy: 0.0926 - val_loss: 1.7290 - val_accuracy: 0.0215\n",
            "Epoch 535/600\n",
            "32/32 [==============================] - 16s 506ms/step - loss: 0.6793 - accuracy: 0.0943 - val_loss: 1.7307 - val_accuracy: 0.0230\n",
            "Epoch 536/600\n",
            "32/32 [==============================] - 15s 479ms/step - loss: 0.6869 - accuracy: 0.0936 - val_loss: 1.7276 - val_accuracy: 0.0215\n",
            "Epoch 537/600\n",
            "32/32 [==============================] - 15s 472ms/step - loss: 0.6778 - accuracy: 0.0956 - val_loss: 1.7292 - val_accuracy: 0.0215\n",
            "Epoch 538/600\n",
            "32/32 [==============================] - 15s 480ms/step - loss: 0.6774 - accuracy: 0.0946 - val_loss: 1.7232 - val_accuracy: 0.0220\n",
            "Epoch 539/600\n",
            "32/32 [==============================] - 15s 482ms/step - loss: 0.6800 - accuracy: 0.0944 - val_loss: 1.7207 - val_accuracy: 0.0233\n",
            "Epoch 540/600\n",
            "32/32 [==============================] - 16s 518ms/step - loss: 0.6880 - accuracy: 0.0919 - val_loss: 1.7200 - val_accuracy: 0.0215\n",
            "Epoch 541/600\n",
            "32/32 [==============================] - 16s 508ms/step - loss: 0.6748 - accuracy: 0.0947 - val_loss: 1.7378 - val_accuracy: 0.0223\n",
            "Epoch 542/600\n",
            "32/32 [==============================] - 17s 523ms/step - loss: 0.6770 - accuracy: 0.0948 - val_loss: 1.7297 - val_accuracy: 0.0217\n",
            "Epoch 543/600\n",
            "32/32 [==============================] - 16s 507ms/step - loss: 0.6827 - accuracy: 0.0946 - val_loss: 1.7372 - val_accuracy: 0.0235\n",
            "Epoch 544/600\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 0.6868 - accuracy: 0.0938 - val_loss: 1.7143 - val_accuracy: 0.0243\n",
            "Epoch 545/600\n",
            "32/32 [==============================] - 16s 502ms/step - loss: 0.6962 - accuracy: 0.0927 - val_loss: 1.7333 - val_accuracy: 0.0223\n",
            "Epoch 546/600\n",
            "32/32 [==============================] - 16s 511ms/step - loss: 0.6842 - accuracy: 0.0935 - val_loss: 1.7188 - val_accuracy: 0.0227\n",
            "Epoch 547/600\n",
            "32/32 [==============================] - 16s 485ms/step - loss: 0.6749 - accuracy: 0.0959 - val_loss: 1.7350 - val_accuracy: 0.0210\n",
            "Epoch 548/600\n",
            "32/32 [==============================] - 17s 526ms/step - loss: 0.6718 - accuracy: 0.0954 - val_loss: 1.7302 - val_accuracy: 0.0213\n",
            "Epoch 549/600\n",
            "32/32 [==============================] - 15s 466ms/step - loss: 0.6712 - accuracy: 0.0961 - val_loss: 1.7281 - val_accuracy: 0.0227\n",
            "Epoch 550/600\n",
            "32/32 [==============================] - 15s 475ms/step - loss: 0.6768 - accuracy: 0.0968 - val_loss: 1.7243 - val_accuracy: 0.0215\n",
            "Epoch 551/600\n",
            "32/32 [==============================] - 17s 517ms/step - loss: 0.6692 - accuracy: 0.0964 - val_loss: 1.7167 - val_accuracy: 0.0217\n",
            "Epoch 552/600\n",
            "32/32 [==============================] - 16s 500ms/step - loss: 0.6756 - accuracy: 0.0947 - val_loss: 1.7209 - val_accuracy: 0.0227\n",
            "Epoch 553/600\n",
            "32/32 [==============================] - 15s 460ms/step - loss: 0.6680 - accuracy: 0.0964 - val_loss: 1.7376 - val_accuracy: 0.0223\n",
            "Epoch 554/600\n",
            "32/32 [==============================] - 16s 485ms/step - loss: 0.6606 - accuracy: 0.0986 - val_loss: 1.7367 - val_accuracy: 0.0225\n",
            "Epoch 555/600\n",
            "32/32 [==============================] - 16s 503ms/step - loss: 0.6606 - accuracy: 0.0979 - val_loss: 1.7259 - val_accuracy: 0.0220\n",
            "Epoch 556/600\n",
            "32/32 [==============================] - 16s 498ms/step - loss: 0.6632 - accuracy: 0.0983 - val_loss: 1.7426 - val_accuracy: 0.0220\n",
            "Epoch 557/600\n",
            "32/32 [==============================] - 14s 445ms/step - loss: 0.6767 - accuracy: 0.0955 - val_loss: 1.7470 - val_accuracy: 0.0225\n",
            "Epoch 558/600\n",
            "32/32 [==============================] - 15s 472ms/step - loss: 0.6713 - accuracy: 0.0964 - val_loss: 1.7384 - val_accuracy: 0.0217\n",
            "Epoch 559/600\n",
            "32/32 [==============================] - 16s 490ms/step - loss: 0.6639 - accuracy: 0.0971 - val_loss: 1.7375 - val_accuracy: 0.0217\n",
            "Epoch 560/600\n",
            "32/32 [==============================] - 16s 487ms/step - loss: 0.6677 - accuracy: 0.0964 - val_loss: 1.7366 - val_accuracy: 0.0225\n",
            "Epoch 561/600\n",
            "32/32 [==============================] - 18s 552ms/step - loss: 0.6686 - accuracy: 0.0964 - val_loss: 1.7546 - val_accuracy: 0.0225\n",
            "Epoch 562/600\n",
            "32/32 [==============================] - 16s 507ms/step - loss: 0.6603 - accuracy: 0.0979 - val_loss: 1.7554 - val_accuracy: 0.0220\n",
            "Epoch 563/600\n",
            "32/32 [==============================] - 17s 526ms/step - loss: 0.7314 - accuracy: 0.0868 - val_loss: 1.7466 - val_accuracy: 0.0207\n",
            "Epoch 564/600\n",
            "32/32 [==============================] - 16s 489ms/step - loss: 0.7515 - accuracy: 0.0836 - val_loss: 1.7256 - val_accuracy: 0.0227\n",
            "Epoch 565/600\n",
            "32/32 [==============================] - 16s 487ms/step - loss: 0.7144 - accuracy: 0.0897 - val_loss: 1.7609 - val_accuracy: 0.0233\n",
            "Epoch 566/600\n",
            "32/32 [==============================] - 15s 464ms/step - loss: 0.7120 - accuracy: 0.0908 - val_loss: 1.7503 - val_accuracy: 0.0210\n",
            "Epoch 567/600\n",
            "32/32 [==============================] - 15s 472ms/step - loss: 0.7008 - accuracy: 0.0924 - val_loss: 1.7369 - val_accuracy: 0.0217\n",
            "Epoch 568/600\n",
            "32/32 [==============================] - 16s 490ms/step - loss: 0.6893 - accuracy: 0.0955 - val_loss: 1.7469 - val_accuracy: 0.0223\n",
            "Epoch 569/600\n",
            "32/32 [==============================] - 15s 480ms/step - loss: 0.6931 - accuracy: 0.0932 - val_loss: 1.7300 - val_accuracy: 0.0223\n",
            "Epoch 570/600\n",
            "32/32 [==============================] - 17s 527ms/step - loss: 0.7049 - accuracy: 0.0921 - val_loss: 1.7263 - val_accuracy: 0.0243\n",
            "Epoch 571/600\n",
            "32/32 [==============================] - 15s 482ms/step - loss: 0.6757 - accuracy: 0.0966 - val_loss: 1.7578 - val_accuracy: 0.0213\n",
            "Epoch 572/600\n",
            "32/32 [==============================] - 15s 480ms/step - loss: 0.6654 - accuracy: 0.0979 - val_loss: 1.7459 - val_accuracy: 0.0215\n",
            "Epoch 573/600\n",
            "32/32 [==============================] - 17s 519ms/step - loss: 0.6620 - accuracy: 0.0988 - val_loss: 1.7441 - val_accuracy: 0.0210\n",
            "Epoch 574/600\n",
            "32/32 [==============================] - 16s 500ms/step - loss: 0.6831 - accuracy: 0.0945 - val_loss: 1.7335 - val_accuracy: 0.0243\n",
            "Epoch 575/600\n",
            "32/32 [==============================] - 15s 481ms/step - loss: 0.6605 - accuracy: 0.0992 - val_loss: 1.7346 - val_accuracy: 0.0233\n",
            "Epoch 576/600\n",
            "32/32 [==============================] - 14s 450ms/step - loss: 0.6597 - accuracy: 0.0989 - val_loss: 1.7393 - val_accuracy: 0.0227\n",
            "Epoch 577/600\n",
            "32/32 [==============================] - 16s 486ms/step - loss: 0.6575 - accuracy: 0.0988 - val_loss: 1.7456 - val_accuracy: 0.0225\n",
            "Epoch 578/600\n",
            "32/32 [==============================] - 16s 507ms/step - loss: 0.6600 - accuracy: 0.0979 - val_loss: 1.7360 - val_accuracy: 0.0225\n",
            "Epoch 579/600\n",
            "32/32 [==============================] - 15s 484ms/step - loss: 0.6625 - accuracy: 0.0976 - val_loss: 1.7209 - val_accuracy: 0.0227\n",
            "Epoch 580/600\n",
            "32/32 [==============================] - 16s 508ms/step - loss: 0.6881 - accuracy: 0.0930 - val_loss: 1.7511 - val_accuracy: 0.0223\n",
            "Epoch 581/600\n",
            "32/32 [==============================] - 15s 472ms/step - loss: 0.6666 - accuracy: 0.0973 - val_loss: 1.7460 - val_accuracy: 0.0213\n",
            "Epoch 582/600\n",
            "32/32 [==============================] - 15s 481ms/step - loss: 0.6556 - accuracy: 0.0983 - val_loss: 1.7269 - val_accuracy: 0.0223\n",
            "Epoch 583/600\n",
            "32/32 [==============================] - 16s 489ms/step - loss: 0.6516 - accuracy: 0.0996 - val_loss: 1.7419 - val_accuracy: 0.0213\n",
            "Epoch 584/600\n",
            "32/32 [==============================] - 15s 485ms/step - loss: 0.6531 - accuracy: 0.0998 - val_loss: 1.7271 - val_accuracy: 0.0217\n",
            "Epoch 585/600\n",
            "32/32 [==============================] - 17s 536ms/step - loss: 0.6658 - accuracy: 0.0981 - val_loss: 1.7374 - val_accuracy: 0.0225\n",
            "Epoch 586/600\n",
            "32/32 [==============================] - 16s 493ms/step - loss: 0.6482 - accuracy: 0.1013 - val_loss: 1.7212 - val_accuracy: 0.0227\n",
            "Epoch 587/600\n",
            "32/32 [==============================] - 15s 477ms/step - loss: 0.6487 - accuracy: 0.0997 - val_loss: 1.7513 - val_accuracy: 0.0225\n",
            "Epoch 588/600\n",
            "32/32 [==============================] - 16s 487ms/step - loss: 0.6500 - accuracy: 0.0992 - val_loss: 1.7413 - val_accuracy: 0.0227\n",
            "Epoch 589/600\n",
            "32/32 [==============================] - 16s 501ms/step - loss: 0.6455 - accuracy: 0.1023 - val_loss: 1.7420 - val_accuracy: 0.0217\n",
            "Epoch 590/600\n",
            "32/32 [==============================] - 18s 566ms/step - loss: 0.6437 - accuracy: 0.1014 - val_loss: 1.7557 - val_accuracy: 0.0210\n",
            "Epoch 591/600\n",
            "32/32 [==============================] - 16s 495ms/step - loss: 0.6452 - accuracy: 0.1004 - val_loss: 1.7369 - val_accuracy: 0.0227\n",
            "Epoch 592/600\n",
            "32/32 [==============================] - 16s 502ms/step - loss: 0.6464 - accuracy: 0.1010 - val_loss: 1.7533 - val_accuracy: 0.0230\n",
            "Epoch 593/600\n",
            "32/32 [==============================] - 16s 509ms/step - loss: 0.6370 - accuracy: 0.1028 - val_loss: 1.7539 - val_accuracy: 0.0225\n",
            "Epoch 594/600\n",
            "32/32 [==============================] - 16s 494ms/step - loss: 0.6378 - accuracy: 0.1029 - val_loss: 1.7448 - val_accuracy: 0.0227\n",
            "Epoch 595/600\n",
            "32/32 [==============================] - 16s 486ms/step - loss: 0.6445 - accuracy: 0.1019 - val_loss: 1.7528 - val_accuracy: 0.0225\n",
            "Epoch 596/600\n",
            "32/32 [==============================] - 15s 458ms/step - loss: 0.6312 - accuracy: 0.1030 - val_loss: 1.7449 - val_accuracy: 0.0217\n",
            "Epoch 597/600\n",
            "32/32 [==============================] - 15s 471ms/step - loss: 0.6301 - accuracy: 0.1023 - val_loss: 1.7664 - val_accuracy: 0.0217\n",
            "Epoch 598/600\n",
            "32/32 [==============================] - 15s 484ms/step - loss: 0.6368 - accuracy: 0.1021 - val_loss: 1.7336 - val_accuracy: 0.0220\n",
            "Epoch 599/600\n",
            "32/32 [==============================] - 17s 550ms/step - loss: 0.6358 - accuracy: 0.1024 - val_loss: 1.7808 - val_accuracy: 0.0227\n",
            "Epoch 600/600\n",
            "32/32 [==============================] - 15s 475ms/step - loss: 0.6347 - accuracy: 0.1023 - val_loss: 1.7598 - val_accuracy: 0.0213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "training_model = load_model('training_model.h5')\n",
        "encoder_inputs = training_model.input[0]\n",
        "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "latent_dim = 256\n",
        "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
        "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
        "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_hidden, state_cell]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "def decode_response(test_input):\n",
        "    #Getting the output states to pass into the decoder\n",
        "    states_value = encoder_model.predict(test_input)\n",
        "    #Generating empty target sequence of length 1\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    #Setting the first token of target sequence with the start token\n",
        "    target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
        "    \n",
        "    #A variable to store our response word by word\n",
        "    decoded_sentence = ''\n",
        "    \n",
        "    stop_condition = False\n",
        "    while not stop_condition:\n",
        "          #Predicting output tokens with probabilities and states\n",
        "          output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
        "    #Choosing the one with highest probability\n",
        "          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "          sampled_token = reverse_target_features_dict[sampled_token_index]\n",
        "          decoded_sentence += \" \" + sampled_token\n",
        "    #Stop if hit max length or found the stop token\n",
        "          if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "    #Update the target sequence\n",
        "          target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "          target_seq[0, 0, sampled_token_index] = 1.\n",
        "          #Update states\n",
        "          states_value = [hidden_state, cell_state]\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "a5woRvwgr4XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatBot:\n",
        "  negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n",
        "  exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n",
        "#Method to start the conversation\n",
        "  def start_chat(self):\n",
        "    user_response = input(\"Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\\n\")\n",
        "    \n",
        "    if user_response in self.negative_responses:\n",
        "      print(\"Ok, have a great day!\")\n",
        "      return\n",
        "    self.chat(user_response)\n",
        "#Method to handle the conversation\n",
        "  def chat(self, reply):\n",
        "    while not self.make_exit(reply):\n",
        "      reply = input(self.generate_response(reply)+\"\\n\")\n",
        "    \n",
        "  #Method to convert user input into a matrix\n",
        "  def string_to_matrix(self, user_input):\n",
        "    tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
        "    user_input_matrix = np.zeros(\n",
        "      (1, max_encoder_seq_length, num_encoder_tokens),\n",
        "      dtype='float32')\n",
        "    for timestep, token in enumerate(tokens):\n",
        "      if token in input_features_dict:\n",
        "        user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
        "    return user_input_matrix\n",
        "  \n",
        "  #Method that will create a response using seq2seq model we built\n",
        "  def generate_response(self, user_input):\n",
        "    input_matrix = self.string_to_matrix(user_input)\n",
        "    chatbot_response = decode_response(input_matrix)\n",
        "    #Remove <START> and <END> tokens from chatbot_response\n",
        "    chatbot_response = chatbot_response.replace(\"<START>\",'')\n",
        "    chatbot_response = chatbot_response.replace(\"<END>\",'')\n",
        "    return chatbot_response\n",
        "#Method to check for exit commands\n",
        "  def make_exit(self, reply):\n",
        "    for exit_command in self.exit_commands:\n",
        "      if exit_command in reply:\n",
        "        print(\"Ok, have a great day!\")\n",
        "        return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "SJrI9jZ2r9qL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = ChatBot()\n",
        "chatbot.start_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh0wfzDF30A-",
        "outputId": "c51b9cc1-b896-4fd3-d130-843bf4d7f6b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\n",
            "yeah i would like to\n",
            " ok \n",
            "what can you do\n"
          ]
        }
      ]
    }
  ]
}